<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh_Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">




  


  <link rel="alternate" href="/atom.xml" title="态度" type="application/atom+xml">






<meta name="description" content="Centos-7 部署openstack-pike步骤详解加入老张：作者老张关注老张微信公众号： 有疑问单独联系老张： 一、    环境准备：控制节点与计算节点都做环境部署1.1   两台虚拟机两台centos-7虚拟机：一台控制节点（controller）：  4G内存、1核、双网卡一台计算节点（computer）：  4G内存、1核、双网卡、修改/etc/hosts配置文件，进行修改主机名。">
<meta property="og:type" content="article">
<meta property="og:title" content="Centos-7搭建openstack、">
<meta property="og:url" content="http://yoursite.com/2018/11/05/Centos-7搭建openstack、/index.html">
<meta property="og:site_name" content="态度">
<meta property="og:description" content="Centos-7 部署openstack-pike步骤详解加入老张：作者老张关注老张微信公众号： 有疑问单独联系老张： 一、    环境准备：控制节点与计算节点都做环境部署1.1   两台虚拟机两台centos-7虚拟机：一台控制节点（controller）：  4G内存、1核、双网卡一台计算节点（computer）：  4G内存、1核、双网卡、修改/etc/hosts配置文件，进行修改主机名。">
<meta property="og:locale" content="zh_Hans">
<meta property="og:updated_time" content="2018-11-05T12:13:04.845Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Centos-7搭建openstack、">
<meta name="twitter:description" content="Centos-7 部署openstack-pike步骤详解加入老张：作者老张关注老张微信公众号： 有疑问单独联系老张： 一、    环境准备：控制节点与计算节点都做环境部署1.1   两台虚拟机两台centos-7虚拟机：一台控制节点（controller）：  4G内存、1核、双网卡一台计算节点（computer）：  4G内存、1核、双网卡、修改/etc/hosts配置文件，进行修改主机名。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/11/05/Centos-7搭建openstack、/">





  <title>Centos-7搭建openstack、 | 态度</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh_Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">态度</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">命运掌握在自己手中，从不向命运低头</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/05/Centos-7搭建openstack、/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="态度">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="态度">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Centos-7搭建openstack、</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-05T20:11:45+08:00">
                2018-11-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Centos-7 部署openstack-pike步骤详解<br>加入老张：<br>作者老张<br>关注老张微信公众号：</p>
<p>有疑问单独联系老张：</p>
<p>一、    环境准备：<br>控制节点与计算节点都做环境部署<br>1.1   两台虚拟机<br>两台centos-7虚拟机：<br>一台控制节点（controller）：  4G内存、1核、双网卡<br>一台计算节点（computer）：  4G内存、1核、双网卡、<br>修改/etc/hosts配置文件，进行修改主机名。</p>
<p>#173.168.6.15    controller</p>
<p>#173.168.6.200   computer</p>
<p>将controller和compute的第一块网卡变成网络接口<br>因为给每台机器配置了两个网卡，先只需将controller和compute的第一个接口变成网络接口。<br>将controller和compute的第二块网卡作为provider网络打开第二个网卡#vi   /etc/sysconfig/network-scripts/ifcfg-INTERFACE_NAME<br>配置完后: systemctl   restart  network  重启网络<br>1.2、关闭防火墙和上下文</p>
<p>systemctl   stop  firewalld.service<br>systemctl    disable  firewalld.service  永久关闭防火墙<br>setenforcec    0 （设置selinux为允许模式）或者编辑/etc/selinux/cocnfig<br>文件把enforce 改成disable<br>1.3、配置网络yum仓库<br>进入 cd  /etc/yum.repos.d  目录下<br>输入命令wget  <a href="http://mirrors.aliyun.com/repo/Centos-7.repo" target="_blank" rel="noopener">http://mirrors.aliyun.com/repo/Centos-7.repo</a><br>将阿里云的yum源下载到本地使用，执行这条命令后yum仓库里就有了阿里的yum源，需要把其他的yum源删除，执行yum  clean all 删除系统缓存yum，然后执行yum  update 更新yum更新完成后就可以使用网络yum了。<br>1.4   安装并配置chrony</p>
<p>#yum install chrony<br>对于RHEL，CentOS或SUSE，请编辑该/etc/chrony.conf文件：<br>$Server  controller<br>$Allow  173.168.6.0/24 （允许173.168.6.0网段的节点连接到控制节点上）<br>开启chrony</p>
<h1 id="systemctl-enable-chronyd-service"><a href="#systemctl-enable-chronyd-service" class="headerlink" title="systemctl enable chronyd.service"></a>systemctl enable chronyd.service</h1><h1 id="systemctl-start-chronyd-service"><a href="#systemctl-start-chronyd-service" class="headerlink" title="systemctl start chronyd.service"></a>systemctl start chronyd.service</h1><p>校验：<br>chronyc   sources<br>控制节点：</p>
<p>其他节点：</p>
<p>1.5、安装Openstack包<br>安装openstack最新的源：</p>
<p>#yum install centos-release-openstack-pike</p>
<p>#yum upgrade    （安装完openstack后在主机上升级包出现新的内核重启系统激活内核）</p>
<p>#yum install python-openstackclient         （安装opentack必须的插件）</p>
<p>#yum install openstack-selinux</p>
<p>1.6、安装配置mysql  和pymsql<br>大多数OpenStack服务使用SQL数据库来存储信息。数据库通常在控制器节点上运行。本指南中的程序根据分布使用MariaDB或MySQL。OpenStack服务还支持其他SQL数据库，包括 PostgreSQL。<br>安装软件包：</p>
<h1 id="yum-install-mariadb-mariadb-server-python2-PyMySQL"><a href="#yum-install-mariadb-mariadb-server-python2-PyMySQL" class="headerlink" title="yum install mariadb mariadb-server python2-PyMySQL"></a>yum install mariadb mariadb-server python2-PyMySQL</h1><p>创建并编辑该/etc/my.cnf.d/openstack.cnf文件（/etc/my.cnf.d/如果需要，备份现有配置文件）并完成以下操作：<br>创建一个[mysqld]部分，并将bind-address 密钥设置为控制器节点的管理IP地址，以使其他节点能够通过管理网络进行访问。设置其他键以启用有用的选项和UTF-8字符集：<br>[mysqld]<br>bind-address = 10.0.0.11（本机地址）</p>
<p>default-storage-engine = innodb<br>innodb_file_per_table = on<br>max_connections = 4096<br>collation-server = utf8_general_ci<br>character-set-server = utf8</p>
<p>完成安装以后启动mariadb服务：</p>
<h1 id="systemctl-enable-mariadb-service"><a href="#systemctl-enable-mariadb-service" class="headerlink" title="systemctl enable mariadb.service"></a>systemctl enable mariadb.service</h1><h1 id="systemctl-start-mariadb-service"><a href="#systemctl-start-mariadb-service" class="headerlink" title="systemctl start mariadb.service"></a>systemctl start mariadb.service</h1><p>通过运行mysql_secure_installation 脚本来保护数据库服务。特别是，为数据库root帐户选择一个合适的密码 ：</p>
<h1 id="mysql-secure-installation"><a href="#mysql-secure-installation" class="headerlink" title="mysql_secure_installation"></a>mysql_secure_installation</h1><p>1.7    rabbitmq（消息队列）安装<br>OpenStack使用消息队列来协调服务之间的操作和状态信息。消息队列服务通常在控制器节点上运行。OpenStack支持多种消息队列服务，包括RabbitMQ， Qpid和ZeroMQ。但是，包装OpenStack的大多数发行版都支持特定的消息队列服务。本指南实现了RabbitMQ消息队列服务，因为大多数发行版都支持它。如果您更喜欢实施不同的消息队列服务，请参阅与其相关的文档。</p>
<p>消息队列在控制器节点上运行。<br>安装软件包：</p>
<h1 id="yum-install-rabbitmq-server"><a href="#yum-install-rabbitmq-server" class="headerlink" title="yum install rabbitmq-server"></a>yum install rabbitmq-server</h1><p>启动消息队列服务并将其配置为在系统引导时启动：</p>
<h1 id="systemctl-enable-rabbitmq-server-service"><a href="#systemctl-enable-rabbitmq-server-service" class="headerlink" title="systemctl enable  rabbitmq-server.service"></a>systemctl enable  rabbitmq-server.service</h1><h1 id="systemctl-start-rabbitmq-server-service"><a href="#systemctl-start-rabbitmq-server-service" class="headerlink" title="systemctl start  rabbitmq-server.service"></a>systemctl start  rabbitmq-server.service</h1><p>添加openstack用户：</p>
<h1 id="rabbitmqctl-add-user-openstack-RABBIT-PASS"><a href="#rabbitmqctl-add-user-openstack-RABBIT-PASS" class="headerlink" title="rabbitmqctl add_user openstack RABBIT_PASS"></a>rabbitmqctl add_user openstack RABBIT_PASS</h1><p>Creating user “openstack” …</p>
<p>注：用RABBIT_PASS适当的密码替换。<br>允许用户进行配置，写入和读取访问 openstack：</p>
<h1 id="rabbitmqctl-set-permissions-openstack-“-“-“-“-“-”"><a href="#rabbitmqctl-set-permissions-openstack-“-“-“-“-“-”" class="headerlink" title="rabbitmqctl set_permissions openstack “.“ “.“ “.*”"></a>rabbitmqctl set_permissions openstack “.<em>“ “.</em>“ “.*”</h1><p>Setting permissions for user “openstack” in vhost “/“ …</p>
<p>开启rabbitmq服务：<br>systemctl  enable  rabbitmq-erver.service<br>systemctl   start   rabbitmq-erver.service<br>1.8    Memcached 安装与配置<br>服务的身份认证服务使用Memcached缓存令牌。memcached服务通常在控制器节点上运行。对于生产部署，我们建议启用防火墙，身份验证和加密的组合来保护它。<br>安装软件包：</p>
<h1 id="yum-install-memcached-python-memcached"><a href="#yum-install-memcached-python-memcached" class="headerlink" title="yum install memcached python-memcached"></a>yum install memcached python-memcached</h1><p>编辑/etc/sysconfig/memcached文件并完成以下操作：<br>配置服务以使用控制器节点的管理IP地址。这是为了使其他节点能够通过管理网络进行访问：<br>OPTIONS=”-l 127.0.0.1,::1,controller”</p>
<p>注意：更改现有的行。OPTIONS=”-l 127.0.0.1,::1”<br>完成安装启动Memcached服务并将其配置为在系统引导时启动：</p>
<h1 id="systemctl-enable-memcached-service"><a href="#systemctl-enable-memcached-service" class="headerlink" title="systemctl enable memcached.service"></a>systemctl enable memcached.service</h1><h1 id="systemctl-start-memcached-service"><a href="#systemctl-start-memcached-service" class="headerlink" title="systemctl start memcached.service"></a>systemctl start memcached.service</h1><p>1.9   etcd部件安装与配置<br>只在控制节点做<br>安装软件包：</p>
<h1 id="yum-install-etcd"><a href="#yum-install-etcd" class="headerlink" title="yum install etcd"></a>yum install etcd</h1><p>编辑/etc/etcd/etcd.conf文件并设置ETCD_INITIAL_CLUSTER， ETCD_INITIAL_ADVERTISE_PEER_URLS，ETCD_ADVERTISE_CLIENT_URLS， ETCD_LISTEN_CLIENT_URLS控制器节点，以使经由管理网络通过其他节点的访问的管理IP地址：</p>
<p>#[Member]<br>ETCD_DATA_DIR=”/var/lib/etcd/default.etcd”<br>ETCD_LISTEN_PEER_URLS=”<a href="http://10.0.0.11:2380&quot;" target="_blank" rel="noopener">http://10.0.0.11:2380&quot;</a><br>ETCD_LISTEN_CLIENT_URLS=”<a href="http://10.0.0.11:2379&quot;" target="_blank" rel="noopener">http://10.0.0.11:2379&quot;</a><br>ETCD_NAME=”controller”</p>
<p>#[Clustering]<br>ETCD_INITIAL_ADVERTISE_PEER_URLS=”<a href="http://10.0.0.11:2380&quot;" target="_blank" rel="noopener">http://10.0.0.11:2380&quot;</a><br>ETCD_ADVERTISE_CLIENT_URLS=”<a href="http://10.0.0.11:2379&quot;" target="_blank" rel="noopener">http://10.0.0.11:2379&quot;</a><br>ETCD_INITIAL_CLUSTER=”controller=<a href="http://10.0.0.11:2380&quot;" target="_blank" rel="noopener">http://10.0.0.11:2380&quot;</a><br>ETCD_INITIAL_CLUSTER_TOKEN=”etcd-cluster-01”<br>ETCD_INITIAL_CLUSTER_STATE=”new”<br>注：上面的地址修改成自己本机的IP地址。<br>安装完成启用并启动etcd服务：</p>
<h1 id="systemctl-enable-etcd"><a href="#systemctl-enable-etcd" class="headerlink" title="systemctl enable etcd"></a>systemctl enable etcd</h1><h1 id="systemctl-start-etcd"><a href="#systemctl-start-etcd" class="headerlink" title="systemctl start etcd"></a>systemctl start etcd</h1><p>二、    认证服务（Identity service – keystone installation for Pike）：<br>OpenStack身份识别服务为管理身份验证，授权和服务目录提供了单点集成。<br>身份服务通常是用户与之交互的第一个服务。一旦通过身份验证，最终用户就可以使用他们的身份访问其他OpenStack服务。同样，其他OpenStack服务利用身份服务来确保用户是他们所说的人，并发现部署中其他服务的位置。身份识别服务还可以与一些外部用户管理系统（如LDAP）集成。<br>用户和服务可以通过使用由身份服务管理的服务目录来定位其他服务。顾名思义，服务目录是OpenStack部署中可用服务的集合。每个服务可以有一个或多个端点，每个端点可以是以下三种类型之一：admin，internal或public。在生产环境中，出于安全原因，不同类型的终端类型可能会驻留在暴露给不同类型用户的单独网络中。例如，公共API网络可能从互联网上可见，因此客户可以管理他们的云。管理API网络可能仅限于管理云基础架构的组织中的运营商。内部API网络可能仅限于包含OpenStack服务的主机。另外，OpenStack支持多个区域的可伸缩性。RegionOne地区。在身份服务中创建的区域，服务和端点一起构成部署的服务目录。部署中的每个OpenStack服务都需要一个服务条目，并在Identity服务中存储相应的端点。这可以在Identity Service安装和配置完成后完成。<br>身份服务包含以下组件：<br>服务器<br>集中式服务器使用RESTful接口提供认证和授权服务。<br>驱动程序<br>驱动程序或服务后端集成到中央服务器。它们用于访问OpenStack外部的存储库中的身份信息，并且可能已经存在于部署OpenStack的基础架构（例如SQL数据库或LDAP服务器）中。<br>模块<br>中间件模块运行在使用Identity服务的OpenStack组件的地址空间中。这些模块拦截服务请求，提取用户凭据并将其发送到中央服务器进行授权。中间件模块和OpenStack组件之间的集成使用Python Web服务器网关接口。<br>本节介绍如何在控制器节点上安装和配置代码为keystone的OpenStack Identity服务。为了扩展性，这个配置部署了Fernet令牌和Apache HTTP服务器来处理请求。<br>在安装和配置Identity Service之前，您必须创建一个数据库。<br>2.1  创建keystone数据库<br>使用数据库访问客户端以root用户身份连接到数据库服务器：<br>$ mysql -u root -p<br>创建keystone数据库：<br>MariaDB [(none)]&gt; CREATE DATABASE keystone;<br>授予对keystone数据库的适当访问权限：<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.<em> TO ‘keystone‘@’localhost’ IDENTIFIED BY ‘KEYSTONE_DBPASS’;<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.</em> TO ‘keystone‘@’%’ IDENTIFIED BY ‘KEYSTONE_DBPASS’;<br>注: 用KEYSTONE_DBPASS适当的密码替换。<br>2.2  安装和配置keystone的部件<br>注意：默认配置文件因分布而异。您可能需要添加这些部分和选项，而不是修改现有部分和选项。此外，…配置片段中的省略号（）指示您应该保留的潜在默认配置选项。<br>注意：本指南使用Apache HTTP服务器mod_wsgi在端口5000和35357上提供身份服务请求。默认情况下，keystone服务仍监听这些端口。因此，本指南手动禁用keystone服务。<br>运行以下命令来安装软件包：</p>
<h1 id="yum-install-openstack-keystone-httpd-mod-wsgi"><a href="#yum-install-openstack-keystone-httpd-mod-wsgi" class="headerlink" title="yum install openstack-keystone httpd mod_wsgi"></a>yum install openstack-keystone httpd mod_wsgi</h1><p>编辑/etc/keystone/keystone.conf文件并完成以下操作：<br>在该[database]部分中，配置数据库访问：<br>[database]</p>
<h1 id="…"><a href="#…" class="headerlink" title="…"></a>…</h1><p>connection = mysql+pymysql://keystone:KEYSTONE_DBPASS@controller/keystone<br>注：替换KEYSTONE_DBPASS为您为数据库选择的密码；注释掉或删除connection该[database]部分中的其他选项 。<br>在该[token]部分中，配置Fernet令牌提供程序：<br>[token]</p>
<h1 id="…-1"><a href="#…-1" class="headerlink" title="…"></a>…</h1><p>provider = fernet<br>填充身份服务数据库（同步数据库 ）：</p>
<h1 id="su-s-bin-sh-c-“keystone-manage-db-sync”-keystone"><a href="#su-s-bin-sh-c-“keystone-manage-db-sync”-keystone" class="headerlink" title="su -s /bin/sh -c “keystone-manage db_sync” keystone"></a>su -s /bin/sh -c “keystone-manage db_sync” keystone</h1><p>初始化Fernet密钥存储库：</p>
<h1 id="keystone-manage-fernet-setup-–keystone-user-keystone-–keystone-group-keystone"><a href="#keystone-manage-fernet-setup-–keystone-user-keystone-–keystone-group-keystone" class="headerlink" title="keystone-manage fernet_setup –keystone-user keystone –keystone-group keystone"></a>keystone-manage fernet_setup –keystone-user keystone –keystone-group keystone</h1><h1 id="keystone-manage-credential-setup-–keystone-user-keystone-–keystone-group-keystone"><a href="#keystone-manage-credential-setup-–keystone-user-keystone-–keystone-group-keystone" class="headerlink" title="keystone-manage credential_setup –keystone-user keystone –keystone-group keystone"></a>keystone-manage credential_setup –keystone-user keystone –keystone-group keystone</h1><p>引导身份服务：</p>
<h1 id="keystone-manage-bootstrap-–bootstrap-password-ADMIN-PASS"><a href="#keystone-manage-bootstrap-–bootstrap-password-ADMIN-PASS" class="headerlink" title="keystone-manage bootstrap –bootstrap-password ADMIN_PASS \"></a>keystone-manage bootstrap –bootstrap-password ADMIN_PASS \</h1><p>  –bootstrap-admin-url <a href="http://controller:35357/v3/" target="_blank" rel="noopener">http://controller:35357/v3/</a> \<br>  –bootstrap-internal-url <a href="http://controller:5000/v3/" target="_blank" rel="noopener">http://controller:5000/v3/</a> \<br>  –bootstrap-public-url <a href="http://controller:5000/v3/" target="_blank" rel="noopener">http://controller:5000/v3/</a> \<br>  –bootstrap-region-id RegionOne<br>注：替换ADMIN_PASS为管理用户的合适密码。<br>2.3  配置Apache HTTP服务器<br>编辑该/etc/httpd/conf/httpd.conf文件并配置该 ServerName选项以引用控制器节点：</p>
<p>#ServerName controller<br>创建一个指向/usr/share/keystone/wsgi-keystone.conf文件的链接：</p>
<h1 id="ln-s-usr-share-keystone-wsgi-keystone-conf-etc-httpd-conf-d"><a href="#ln-s-usr-share-keystone-wsgi-keystone-conf-etc-httpd-conf-d" class="headerlink" title="ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/"></a>ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/</h1><p>完成安装启动Apache HTTP服务并将其配置为在系统引导时启动：</p>
<h1 id="systemctl-enable-httpd-service"><a href="#systemctl-enable-httpd-service" class="headerlink" title="systemctl enable httpd.service"></a>systemctl enable httpd.service</h1><h1 id="systemctl-start-httpd-service"><a href="#systemctl-start-httpd-service" class="headerlink" title="systemctl start httpd.service"></a>systemctl start httpd.service</h1><p>配置管理帐户：<br>$ export OS_USERNAME=admin<br>$ export OS_PASSWORD=ADMIN_PASS<br>$ export OS_PROJECT_NAME=admin<br>$ export OS_USER_DOMAIN_NAME=Default<br>$ export OS_PROJECT_DOMAIN_NAME=Default<br>$ export OS_AUTH_URL=<a href="http://controller:35357/v3" target="_blank" rel="noopener">http://controller:35357/v3</a><br>$ export OS_IDENTITY_API_VERSION=3<br>注：用keystone-install-configure-rdoADMIN_PASS中的命令替换为使用的密码 。keystone-manage bootstrap。<br>2.4  创建一个域，项目，用户和角色</p>
<p>身份服务为每个OpenStack服务提供身份验证服务。身份验证服务使用域，项目，用户和角色的组合。<br>本指南使用一个服务项目，其中包含您添加到环境中的每项服务的唯一用户。创建service 项目：<br> 注：如果创建存储项目、域、和用户报错（http409）极大可能是以前创建的keystone数据库跟想要创建的数据库产生冲突。<br>解决办法：你应该连接到mysql并执行以下查询删除keystone的数据库，然后再次创建。drop database keystone;而 create database keystone;现在，这将创建一个全新的梯形DB然后在重新配置。现在您需要重新同步db以便执行命令：su -s /bin/sh -c “keystone-manage db_sync” keystone<br>$ openstack project create –domain default \<br>  –description “Service Project” service</p>
<p>+————-+———————————-+<br>| Field       | Value                            |<br>+————-+———————————-+<br>| description | Service Project                  |<br>| domain_id   | default                          |<br>| enabled     | True                             |<br>| id          | 24ac7f19cd944f4cba1d77469b2a73ed |<br>| is_domain   | False                            |<br>| name        | service                          |<br>| parent_id   | default                          |<br>+————-+———————————-+<br>普通（非管理员）任务应该使用非特权项目和用户。作为示例，本指南创建demo项目和用户。<br>创建demo项目：<br>$ openstack project create –domain default \<br>  –description “Demo Project” demo</p>
<p>+————-+———————————-+<br>| Field       | Value                            |<br>+————-+———————————-+<br>| description | Demo Project                     |<br>| domain_id   | default                          |<br>| enabled     | True                             |<br>| id          | 231ad6e7ebba47d6a1e57e1cc07ae446 |<br>| is_domain   | False                            |<br>| name        | demo                             |<br>| parent_id   | default                          |<br>+————-+———————————-+<br>注意：在为此项目创建其他用户时不要重复此步骤。<br>创建demo用户：（会提示你输入密码，输入的密码即为为demo用户设置的密码，这里我默认使用1）<br>$ openstack user create –domain default \<br>  –password-prompt demo</p>
<p>User Password:<br>Repeat User Password:<br>+———————+———————————-+<br>| Field               | Value                            |<br>+———————+———————————-+<br>| domain_id           | default                          |<br>| enabled             | True                             |<br>| id                  | aeda23aa78f44e859900e22c24817832 |<br>| name                | demo                             |<br>| options             | {}                               |<br>| password_expires_at | None                             |<br>+———————+———————————-+<br>创建user角色：<br>$ openstack role create user</p>
<p>+———–+———————————-+<br>| Field     | Value                            |<br>+———–+———————————-+<br>| domain_id | None                             |<br>| id        | 997ce8d05fc143ac97d83fdfb5998552 |<br>| name      | user                             |<br>+———–+———————————-+</p>
<p>将user角色添加到demo项目和用户：<br>$ openstack role add –project demo –user demo user<br>注意：该命令不提供输出，<br>注意：您可以重复此过程来创建其他项目和用户。<br>注：当执行以上几条命令都出现Missing value auth-url required for auth plugin password 错误时，应该重新设置一下admin用户的环境变量，重新激活一下  .admin-openrc<br>2.5  验证操作<br>在安装其他服务之前验证身份服务的操作；在控制节点上执行这些命令。<br>取消设置临时 变量OS_AUTH_URL和OS_PASSWORD环境变量：<br>$ unset OS_AUTH_URL OS_PASSWORD<br>作为admin用户，请求身份验证令牌：<br>$ openstack –os-auth-url <a href="http://controller:35357/v3" target="_blank" rel="noopener">http://controller:35357/v3</a> \<br>  –os-project-domain-name Default –os-user-domain-name Default \<br>  –os-project-name admin –os-username admin token issue</p>
<p>Password:<br>+————+—————————————————————–+<br>| Field      | Value                                                           |<br>+————+—————————————————————–+<br>| expires    | 2016-02-12T20:14:07.056119Z                                     |<br>| id         | gAAAAABWvi7_B8kKQD9wdXac8MoZiQldmjEO643d-e_j-XXq9AmIegIbA7UHGPv |<br>|            | atnN21qtOMjCFWX7BReJEQnVOAj3nclRQgAYRsfSU_MrsuWb4EDtnjU7HEpoBb4 |<br>|            | o6ozsA_NmFWEpLeKy0uNn_WeKbAhYygrsmQGA49dclHVnz-OMVLiyM9ws       |<br>| project_id | 343d245e850143a096806dfaefa9afdc                                |<br>| user_id    | ac3377633149401296f6c0d92d79dc16                                |<br>+————+—————————————————————–+<br>注：该命令使用admin用户的密码。<br>作为demo用户，请求身份验证令牌：<br>$ openstack –os-auth-url <a href="http://controller:5000/v3" target="_blank" rel="noopener">http://controller:5000/v3</a> \<br>  –os-project-domain-name Default –os-user-domain-name Default \<br>  –os-project-name demo –os-username demo token issue</p>
<p>Password:<br>+————+—————————————————————–+<br>| Field      | Value                                                           |<br>+————+—————————————————————–+<br>| expires    | 2016-02-12T20:15:39.014479Z                                     |<br>| id         | gAAAAABWvi9bsh7vkiby5BpCCnc-JkbGhm9wH3fabS_cY7uabOubesi-Me6IGWW |<br>|            | yQqNegDDZ5jw7grI26vvgy1J5nCVwZ_zFRqPiz_qhbq29mgbQLglbkq6FQvzBRQ |<br>|            | JcOzq3uwhzNxszJWmzGC7rJE_H0A_a3UFhqv8M4zMRYSbS2YF0MyFmp_U       |<br>| project_id | ed0b60bf607743088218b0a533d5943f                                |<br>| user_id    | 58126687cbcc4888bfa9ab73a2256f27                                |<br>+————+—————————————————————–+</p>
<p>注意：此命令使用demo 用户和API端口5000 的密码，该端口只允许对Identity Service API进行常规（非管理员）访问。</p>
<p>2.8  创建OpenStack客户端环境脚本<br>创建客户端环境的脚本admin和demo 项目和用户。本指南的未来部分引用这些脚本来为客户端操作加载适当的凭据。注意客户端环境脚本的路径不受限制。为了方便起见，您可以将脚本放置在任何位置，但请确保它们可访问并位于适合您部署的安全位置，因为它们包含敏感凭据。<br>创建并编辑admin-openrc文件并添加以下内容：（此处为为openstack的admin用户设置环境变量）<br>export OS_PROJECT_DOMAIN_NAME=Default<br>export OS_USER_DOMAIN_NAME=Default<br>export OS_PROJECT_NAME=admin<br>export OS_USERNAME=admin<br>export OS_PASSWORD=ADMIN_PASS<br>export OS_AUTH_URL=<a href="http://controller:35357/v3" target="_blank" rel="noopener">http://controller:35357/v3</a><br>export OS_IDENTITY_API_VERSION=3<br>export OS_IMAGE_API_VERSION=2<br>替换ADMIN_PASS为您admin在身份识别服务中为用户选择的密码。<br>创建并编辑demo-openrc文件并添加以下内容：（此处为为openstack的demo用户设置环境变量）<br>export OS_PROJECT_DOMAIN_NAME=Default<br>export OS_USER_DOMAIN_NAME=Default<br>export OS_PROJECT_NAME=demo<br>export OS_USERNAME=demo<br>export OS_PASSWORD=DEMO_PASS<br>export OS_AUTH_URL=<a href="http://controller:5000/v3" target="_blank" rel="noopener">http://controller:5000/v3</a><br>export OS_IDENTITY_API_VERSION=3<br>export OS_IMAGE_API_VERSION=2<br>替换DEMO_PASS为您demo在身份识别服务中为用户选择的密码。<br>使用脚本要以特定项目和用户身份运行客户端，只需在运行客户端环境脚本之前加载相关的客户端环境脚本即可。<br>例如：加载admin-openrc文件以使用Identity服务的位置以及admin项目和用户凭据填充环境变量：<br>$ . admin-openrc<br>请求身份验证令牌：<br>$ openstack token issue</p>
<p>+————+—————————————————————–+<br>| Field      | Value                                                           |<br>+————+—————————————————————–+<br>| expires    | 2016-02-12T20:44:35.659723Z                                     |<br>| id         | gAAAAABWvjYj-Zjfg8WXFaQnUd1DMYTBVrKw4h3fIagi5NoEmh21U72SrRv2trl |<br>|            | JWFYhLi2_uPR31Igf6A8mH2Rw9kv_bxNo1jbLNPLGzW_u5FC7InFqx0yYtTwa1e |<br>|            | eq2b0f6-18KZyQhs7F3teAta143kJEWuNEYET-y7u29y0be1_64KYkM7E       |<br>| project_id | 343d245e850143a096806dfaefa9afdc                                |<br>| user_id    | ac3377633149401296f6c0d92d79dc16                                |<br>+————+—————————————————————–+<br>三、    图像服务（Image service – glance installation for Pike）<br>本节介绍如何在控制器节点上安装和配置代码为glance的Image服务。为了简单起见，该配置将图像存储在本地文件系统上。<br>先决条件：<br>在安装和配置Image服务之前，您必须创建数据库，服务凭据和API端点。<br>3.1  创建glance数据库：<br>使用数据库访问客户端以root用户身份连接到数据库服务器：<br>$ mysql -u root -p<br>创建glance数据库：<br>MariaDB [(none)]&gt; CREATE DATABASE glance;<br>授予对glance数据库的适当访问权限：<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.<em> TO ‘glance‘@’localhost’ \<br>  IDENTIFIED BY ‘GLANCE_DBPASS’;<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.</em> TO ‘glance‘@’%’ \<br>  IDENTIFIED BY ‘GLANCE_DBPASS’;<br>注：用GLANCE_DBPASS适当的密码替换，退出数据库访问客户端。<br>来源admin凭据来访问仅管理员CLI命令：<br>. admin-openrc<br>3.2  创建glance服务凭证：<br>创建glance用户：<br>注：创建glance用户时会提醒你输入密码在此刻输入法密码即为你为glance用户密码。<br>$ openstack user create –domain default –password-prompt glance</p>
<p>User Password:<br>Repeat User Password:<br>+———————+———————————-+<br>| Field               | Value                            |<br>+———————+———————————-+<br>| domain_id           | default                          |<br>| enabled             | True                             |<br>| id                  | 3f4e777c4062483ab8d9edd7dff829df |<br>| name                | glance                           |<br>| options             | {}                               |<br>| password_expires_at | None                             |<br>+———————+———————————-+<br>将admin角色添加到glance用户和 service项目中：<br>$ openstack role add –project service –user glance admin<br>创建glance服务实体：<br>openstack service create –name glance \<br>  –description “OpenStack Image” image</p>
<p>+————-+———————————-+<br>| Field       | Value                            |<br>+————-+———————————-+<br>| description | OpenStack Image                  |<br>| enabled     | True                             |<br>| id          | 8c2c7f1b9b5049ea9e63757b5533e6d2 |<br>| name        | glance                           |<br>| type        | image                            |<br>+————-+———————————-+</p>
<p>3.3  创建图像服务API端点：<br>$ openstack endpoint create –region RegionOne \<br>  image public <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a></p>
<p>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | 340be3625e9b4239a6415d034e98aace |<br>| interface    | public                           |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | 8c2c7f1b9b5049ea9e63757b5533e6d2 |<br>| service_name | glance                           |<br>| service_type | image                            |<br>| url          | <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a>           |<br>+————–+———————————-+</p>
<p>$ openstack endpoint create –region RegionOne \<br>  image internal <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a></p>
<p>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | a6e4b153c2ae4c919eccfdbb7dceb5d2 |<br>| interface    | internal                         |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | 8c2c7f1b9b5049ea9e63757b5533e6d2 |<br>| service_name | glance                           |<br>| service_type | image                            |<br>| url          | <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a>           |<br>+————–+———————————-+</p>
<p>$ openstack endpoint create –region RegionOne \<br>  image admin <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a></p>
<p>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | 0c37ed58103f4300a84ff125a539032d |<br>| interface    | admin                            |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | 8c2c7f1b9b5049ea9e63757b5533e6d2 |<br>| service_name | glance                           |<br>| service_type | image                            |<br>| url          | <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a>           |<br>+————–+———————————-+<br>3.4  安装和配置openstack-glance<br>安装软件包：</p>
<h1 id="yum-install-openstack-glance"><a href="#yum-install-openstack-glance" class="headerlink" title="yum install openstack-glance"></a>yum install openstack-glance</h1><p>编辑/etc/glance/glance-api.conf文件并完成以下操作：<br>在该[database]部分中，配置数据库访问：<br>[database]</p>
<h1 id="…-2"><a href="#…-2" class="headerlink" title="…"></a>…</h1><p>connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance<br>注：替换GLANCE_DBPASS为您为图像服务数据库选择的密码。<br>在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问：<br>[keystone_authtoken]</p>
<h1 id="…-3"><a href="#…-3" class="headerlink" title="…"></a>…</h1><p>auth_uri = <a href="http://controller:5000" target="_blank" rel="noopener">http://controller:5000</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>memcached_servers = controller:11211<br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>project_name = service<br>username = glance<br>password = GLANCE_PASS</p>
<p>[paste_deploy]</p>
<h1 id="…-4"><a href="#…-4" class="headerlink" title="…"></a>…</h1><p>flavor = keystone</p>
<p>注：替换GLANCE_PASS为您glance在身份识别服务中为用户选择的密码 。注释掉或删除该[keystone_authtoken]部分中的其他选项 。<br>在该[glance_store]部分中，配置本地文件系统存储和映像文件的位置：<br>[glance_store]</p>
<h1 id="…-5"><a href="#…-5" class="headerlink" title="…"></a>…</h1><p>stores = file,http<br>default_store = file<br>filesystem_store_datadir = /var/lib/glance/images/<br>编辑/etc/glance/glance-registry.conf文件并完成以下操作：<br>在该[database]部分中，配置数据库访问：<br>[database]</p>
<h1 id="…-6"><a href="#…-6" class="headerlink" title="…"></a>…</h1><p>connection = mysql+pymysql://glance:GLANCE_DBPASS@controller/glance<br>注：替换GLANCE_DBPASS为您为图像服务数据库选择的密码。<br>在[keystone_authtoken]和[paste_deploy]部分中，配置身份服务访问：<br>[keystone_authtoken]</p>
<h1 id="…-7"><a href="#…-7" class="headerlink" title="…"></a>…</h1><p>auth_uri = <a href="http://controller:5000" target="_blank" rel="noopener">http://controller:5000</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>memcached_servers = controller:11211<br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>project_name = service<br>username = glance<br>password = GLANCE_PASS</p>
<p>[paste_deploy]</p>
<h1 id="…-8"><a href="#…-8" class="headerlink" title="…"></a>…</h1><p>flavor = keystone<br>注：替换GLANCE_PASS为您glance在身份识别服务中为用户选择的密码 。注释掉或删除该[keystone_authtoken]部分中的其他选项 。<br>填充图像服务数据库：</p>
<h1 id="su-s-bin-sh-c-“glance-manage-db-sync”-glance"><a href="#su-s-bin-sh-c-“glance-manage-db-sync”-glance" class="headerlink" title="su -s /bin/sh -c “glance-manage db_sync” glance"></a>su -s /bin/sh -c “glance-manage db_sync” glance</h1><p>注：忽略此输出中的任何弃用消息。<br>完成安装：</p>
<h1 id="systemctl-enable-openstack-glance-api-service"><a href="#systemctl-enable-openstack-glance-api-service" class="headerlink" title="systemctl enable openstack-glance-api.service \"></a>systemctl enable openstack-glance-api.service \</h1><p>  openstack-glance-registry.service</p>
<h1 id="systemctl-start-openstack-glance-api-service"><a href="#systemctl-start-openstack-glance-api-service" class="headerlink" title="systemctl start openstack-glance-api.service \"></a>systemctl start openstack-glance-api.service \</h1><p>  openstack-glance-registry.service<br>3.5  验证操作<br>使用CirrOS验证Image服务的操作，这 是一个小型Linux映像，可帮助您测试OpenStack部署。在控制器节点上执行这些命令。</p>
<p>来源admin凭据来访问仅管理员CLI命令：<br>$ . admin-openrc<br>下载源图片：<br>$ wget <a href="http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img" target="_blank" rel="noopener">http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img</a><br>注：wget如果您的发行版不包含它，请安装。<br>使用QCOW2磁盘格式，裸 容器格式和公开可见性将图像上传到Image服务 ，以便所有项目都可以访问它：<br>$ openstack image create “cirros” \<br>  –file cirros-0.3.5-x86_64-disk.img \<br>  –disk-format qcow2 –container-format bare \<br>  –public</p>
<p>+——————+——————————————————+<br>| Field            | Value                                                |<br>+——————+——————————————————+<br>| checksum         | 133eae9fb1c98f45894a4e60d8736619                     |<br>| container_format | bare                                                 |<br>| created_at       | 2015-03-26T16:52:10Z                                 |<br>| disk_format      | qcow2                                                |<br>| file             | /v2/images/cc5c6982-4910-471e-b864-1098015901b5/file |<br>| id               | cc5c6982-4910-471e-b864-1098015901b5                 |<br>| min_disk         | 0                                                    |<br>| min_ram          | 0                                                    |<br>| name             | cirros                                               |<br>| owner            | ae7a98326b9c455588edd2656d723b9d                     |<br>| protected        | False                                                |<br>| schema           | /v2/schemas/image                                    |<br>| size             | 13200896                                             |<br>| status           | active                                               |<br>| tags             |                                                      |<br>| updated_at       | 2015-03-26T16:52:10Z                                 |<br>| virtual_size     | None                                                 |<br>| visibility       | public                                               |<br>+——————+——————————————————+</p>
<p>注：OpenStack动态生成ID，因此您将在示例命令输出中看到不同的值。<br>确认图像上传并验证属性：<br>$ openstack image list</p>
<p>+————————————–+——–+——–+<br>| ID                                   | Name   | Status |<br>+————————————–+——–+——–+<br>| 38047887-61a7-41ea-9b49-27987d5e8bb9 | cirros | active |<br>+————————————–+——–+——–+<br>注:当执行前几条命令报出Missing value auth-url required for auth plugin password 错误时应该重新设置一下环境变量(.admin-penrc)<br>四、    计算服务—控制节点配置（Compute service – nova installation for Pike）<br>本节介绍如何在控制器节点上安装和配置代码为nova的Compute服务。<br>4.1 安装和配置计算节点<br>在安装和配置Compute服务之前，您必须创建数据库，服务凭证和API端点。要创建数据库，请完成以下步骤：<br>使用数据库访问客户端以root用户身份连接到数据库服务器 ：<br>mysql -u root –p<br>创建nova_api，nova和nova_cell0数据库：<br>MariaDB [(none)]&gt; CREATE DATABASE nova_api;<br>MariaDB [(none)]&gt; CREATE DATABASE nova;<br>MariaDB [(none)]&gt; CREATE DATABASE nova_cell0;<br>授予对数据库的适当访问权限：<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.<em> TO ‘nova‘@’localhost’ \<br>  IDENTIFIED BY ‘NOVA_DBPASS’;<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_api.</em> TO ‘nova‘@’%’ \<br>  IDENTIFIED BY ‘NOVA_DBPASS’;</p>
<p>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.<em> TO ‘nova‘@’localhost’ \<br>  IDENTIFIED BY ‘NOVA_DBPASS’;<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.</em> TO ‘nova‘@’%’ \<br>  IDENTIFIED BY ‘NOVA_DBPASS’;</p>
<p>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.<em> TO ‘nova‘@’localhost’ \<br>  IDENTIFIED BY ‘NOVA_DBPASS’;<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova_cell0.</em> TO ‘nova‘@’%’ \<br>  IDENTIFIED BY ‘NOVA_DBPASS’;<br>注：用NOVA_DBPASS适当的密码替换。<br>来源admin凭据来访问仅管理员CLI命令：<br>. admin-openrc<br>4.2  创建计算服务凭据：<br>创建nova用户：（这里提示你输入的密码，就是你将要给nova用户输入的密码）<br>openstack user create –domain default –password-prompt nova</p>
<p>User Password:<br>Repeat User Password:<br>+———————+———————————-+<br>| Field               | Value                            |<br>+———————+———————————-+<br>| domain_id           | default                          |<br>| enabled             | True                             |<br>| id                  | 8a7dbf5279404537b1c7b86c033620fe |<br>| name                | nova                             |<br>| options             | {}                               |<br>| password_expires_at | None                             |<br>+———————+———————————-+<br>将admin角色添加到nova用户：<br>$ openstack role add –project service –user nova admin<br>创建nova服务实体：<br>$ openstack service create –name nova \<br>  –description “OpenStack Compute” compute</p>
<p>+————-+———————————-+<br>| Field       | Value                            |<br>+————-+———————————-+<br>| description | OpenStack Compute                |<br>| enabled     | True                             |<br>| id          | 060d59eac51b4594815603d75a00aba2 |<br>| name        | nova                             |<br>| type        | compute                          |<br>+————-+———————————-+<br>创建Compute API服务端点：<br>$ openstack endpoint create –region RegionOne \<br>  compute public <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a></p>
<p>+————–+——————————————-+<br>| Field        | Value                                     |<br>+————–+——————————————-+<br>| enabled      | True                                      |<br>| id           | 3c1caa473bfe4390a11e7177894bcc7b          |<br>| interface    | public                                    |<br>| region       | RegionOne                                 |<br>| region_id    | RegionOne                                 |<br>| service_id   | 060d59eac51b4594815603d75a00aba2          |<br>| service_name | nova                                      |<br>| service_type | compute                                   |<br>| url          | <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a>               |<br>+————–+——————————————-+</p>
<p>$ openstack endpoint create –region RegionOne \<br>  compute internal <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a></p>
<p>+————–+——————————————-+<br>| Field        | Value                                     |<br>+————–+——————————————-+<br>| enabled      | True                                      |<br>| id           | e3c918de680746a586eac1f2d9bc10ab          |<br>| interface    | internal                                  |<br>| region       | RegionOne                                 |<br>| region_id    | RegionOne                                 |<br>| service_id   | 060d59eac51b4594815603d75a00aba2          |<br>| service_name | nova                                      |<br>| service_type | compute                                   |<br>| url          | <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a>               |<br>+————–+——————————————-+</p>
<p>$ openstack endpoint create –region RegionOne \<br>  compute admin <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a></p>
<p>+————–+——————————————-+<br>| Field        | Value                                     |<br>+————–+——————————————-+<br>| enabled      | True                                      |<br>| id           | 38f7af91666a47cfb97b4dc790b94424          |<br>| interface    | admin                                     |<br>| region       | RegionOne                                 |<br>| region_id    | RegionOne                                 |<br>| service_id   | 060d59eac51b4594815603d75a00aba2          |<br>| service_name | nova                                      |<br>| service_type | compute                                   |<br>| url          | <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a>               |<br>+————–+——————————————-+<br>使用您选择的PLACEMENT_PASS以下内容创建展示位置服务用户<br>$ openstack user create –domain default –password-prompt placement</p>
<p>User Password:<br>Repeat User Password:<br>+———————+———————————-+<br>| Field               | Value                            |<br>+———————+———————————-+<br>| domain_id           | default                          |<br>| enabled             | True                             |<br>| id                  | fa742015a6494a949f67629884fc7ec8 |<br>| name                | placement                        |<br>| options             | {}                               |<br>| password_expires_at | None                             |<br>+———————+———————————-+<br>将位置用户添加到具有管理员角色的服务项目中：<br>$ openstack role add –project service –user placement admin<br>在服务目录中创建Placement API条目：<br>$ openstack service create –name placement –description “Placement API” placement<br>+————-+———————————-+<br>| Field       | Value                            |<br>+————-+———————————-+<br>| description | Placement API                    |<br>| enabled     | True                             |<br>| id          | 2d1a27022e6e4185b86adac4444c495f |<br>| name        | placement                        |<br>| type        | placement                        |<br>+————-+———————————-+<br>创建Placement API服务端点：<br>$ openstack endpoint create –region RegionOne placement public <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a><br>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | 2b1b2637908b4137a9c2e0470487cbc0 |<br>| interface    | public                           |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | 2d1a27022e6e4185b86adac4444c495f |<br>| service_name | placement                        |<br>| service_type | placement                        |<br>| url          | <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a>           |<br>+————–+———————————-+</p>
<p>$ openstack endpoint create –region RegionOne placement internal <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a><br>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | 02bcda9a150a4bd7993ff4879df971ab |<br>| interface    | internal                         |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | 2d1a27022e6e4185b86adac4444c495f |<br>| service_name | placement                        |<br>| service_type | placement                        |<br>| url          | <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a>           |<br>+————–+———————————-+</p>
<p>$ openstack endpoint create –region RegionOne placement admin <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a><br>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | 3d71177b9e0f406f98cbff198d74b182 |<br>| interface    | admin                            |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | 2d1a27022e6e4185b86adac4444c495f |<br>| service_name | placement                        |<br>| service_type | placement                        |<br>| url          | <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a>           |<br>+————–+———————————-+<br>4.3  安装和配置组件<br>安装软件包：</p>
<h1 id="yum-install-openstack-nova-api-openstack-nova-conductor"><a href="#yum-install-openstack-nova-api-openstack-nova-conductor" class="headerlink" title="yum install openstack-nova-api openstack-nova-conductor \"></a>yum install openstack-nova-api openstack-nova-conductor \</h1><p>  openstack-nova-console openstack-nova-novncproxy \<br>  openstack-nova-scheduler openstack-nova-placement-api<br>编辑/etc/nova/nova.conf文件并完成以下操作：<br>在该[DEFAULT]部分中，仅启用计算API和元数据API：<br>[DEFAULT]</p>
<h1 id="…-9"><a href="#…-9" class="headerlink" title="…"></a>…</h1><p>enabled_apis = osapi_compute,metadata<br>在[api_database]和[database]部分中，配置数据库访问：<br>[api_database]</p>
<h1 id="…-10"><a href="#…-10" class="headerlink" title="…"></a>…</h1><p>connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova_api</p>
<p>[database]</p>
<h1 id="…-11"><a href="#…-11" class="headerlink" title="…"></a>…</h1><p>connection = mysql+pymysql://nova:NOVA_DBPASS@controller/nova<br>用NOVA_DBPASS为Compute数据库选择的密码替换。<br>在该[DEFAULT]部分中，配置RabbitMQ消息队列访问：<br>[DEFAULT]</p>
<h1 id="…-12"><a href="#…-12" class="headerlink" title="…"></a>…</h1><p>transport_url = rabbit://openstack:RABBIT_PASS@controller<br>替换RABBIT_PASS为您为该openstack 帐户选择的密码RabbitMQ。<br>在[api]和[keystone_authtoken]部分中，配置身份服务访问：<br>[api]</p>
<h1 id="…-13"><a href="#…-13" class="headerlink" title="…"></a>…</h1><p>auth_strategy = keystone</p>
<p>[keystone_authtoken]</p>
<h1 id="…-14"><a href="#…-14" class="headerlink" title="…"></a>…</h1><p>auth_uri = <a href="http://controller:5000" target="_blank" rel="noopener">http://controller:5000</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>memcached_servers = controller:11211<br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>project_name = service<br>username = nova<br>password = NOVA_PASS<br>替换NOVA_PASS为您nova在身份识别服务中为用户选择的密码。<br>在该[DEFAULT]部分中，将该my_ip选项配置为使用控制器节点的管理接口IP地址：<br>[DEFAULT]</p>
<h1 id="…-15"><a href="#…-15" class="headerlink" title="…"></a>…</h1><p>my_ip = 10.0.0.11<br>在本[DEFAULT]节中，启用对网络服务的支持：<br>[DEFAULT]</p>
<h1 id="…-16"><a href="#…-16" class="headerlink" title="…"></a>…</h1><p>use_neutron = True<br>firewall_driver = nova.virt.firewall.NoopFirewallDriver<br>注：情况下，Compute使用内部防火墙驱动程序。由于网络服务包含防火墙驱动程序，因此您必须使用nova.virt.firewall.NoopFirewallDriver防火墙驱动程序禁用Compute防火墙驱动程序。<br>在本[vnc]节中，将VNC代理配置为使用控制器节点的管理接口IP地址：<br>[vnc]<br>enabled = true</p>
<h1 id="…-17"><a href="#…-17" class="headerlink" title="…"></a>…</h1><p>vncserver_listen = $my_ip<br>vncserver_proxyclient_address = $my_ip<br>在该[glance]部分中，配置Image Service API的位置：<br>[glance]</p>
<h1 id="…-18"><a href="#…-18" class="headerlink" title="…"></a>…</h1><p>api_servers = <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a><br>在该[oslo_concurrency]部分中，配置锁定路径：<br>[oslo_concurrency]</p>
<h1 id="…-19"><a href="#…-19" class="headerlink" title="…"></a>…</h1><p>lock_path = /var/lib/nova/tmp<br>在该[placement]部分中，配置Placement API：<br>[placement]</p>
<h1 id="…-20"><a href="#…-20" class="headerlink" title="…"></a>…</h1><p>os_region_name = RegionOne<br>project_domain_name = Default<br>project_name = service<br>auth_type = password<br>user_domain_name = Default<br>auth_url = <a href="http://controller:35357/v3" target="_blank" rel="noopener">http://controller:35357/v3</a><br>username = placement<br>password = PLACEMENT_PASS<br>替换PLACEMENT_PASS为您placement在身份识别服务中为用户选择的密码 。注释本[placement]节中的任何其他选项。<br>由于包装错误，您必须启用对Placement API的访问权限，方法是将以下配置添加到 /etc/httpd/conf.d/00-nova-placement-api.conf：</p>
<p>&lt;Directory /usr/bin&gt;<br>   <ifversion>= 2.4&gt;<br>      Require all granted<br>   </ifversion><br>   &lt;IfVersion &lt; 2.4&gt;<br>      Order allow,deny<br>      Allow from all<br>   <br><br>重新启动httpd服务：</p>
<h1 id="systemctl-restart-httpd"><a href="#systemctl-restart-httpd" class="headerlink" title="systemctl restart httpd"></a>systemctl restart httpd</h1><p>填充nova-api数据库（忽略任何弃用消息）</p>
<h1 id="su-s-bin-sh-c-“nova-manage-api-db-sync”-nova"><a href="#su-s-bin-sh-c-“nova-manage-api-db-sync”-nova" class="headerlink" title="su -s /bin/sh -c “nova-manage api_db sync” nova"></a>su -s /bin/sh -c “nova-manage api_db sync” nova</h1><p>注册cell0数据库：</p>
<h1 id="su-s-bin-sh-c-“nova-manage-cell-v2-map-cell0”-nova"><a href="#su-s-bin-sh-c-“nova-manage-cell-v2-map-cell0”-nova" class="headerlink" title="su -s /bin/sh -c “nova-manage cell_v2 map_cell0” nova"></a>su -s /bin/sh -c “nova-manage cell_v2 map_cell0” nova</h1><p>创建cell1单元格：</p>
<h1 id="su-s-bin-sh-c-“nova-manage-cell-v2-create-cell-–name-cell1-–verbose”-nova"><a href="#su-s-bin-sh-c-“nova-manage-cell-v2-create-cell-–name-cell1-–verbose”-nova" class="headerlink" title="su -s /bin/sh -c “nova-manage cell_v2 create_cell –name=cell1 –verbose” nova"></a>su -s /bin/sh -c “nova-manage cell_v2 create_cell –name=cell1 –verbose” nova</h1><p>109e1d4b-536a-40d0-83c6-5f121b82b650<br>填充nova数据库：</p>
<h1 id="su-s-bin-sh-c-“nova-manage-db-sync”-nova"><a href="#su-s-bin-sh-c-“nova-manage-db-sync”-nova" class="headerlink" title="su -s /bin/sh -c “nova-manage db sync” nova"></a>su -s /bin/sh -c “nova-manage db sync” nova</h1><p>验证nova cell0和cell1是否正确注册：</p>
<h1 id="nova-manage-cell-v2-list-cells"><a href="#nova-manage-cell-v2-list-cells" class="headerlink" title="nova-manage cell_v2 list_cells"></a>nova-manage cell_v2 list_cells</h1><p>+——-+————————————–+<br>| Name  | UUID                                 |<br>+——-+————————————–+<br>| cell1 | 109e1d4b-536a-40d0-83c6-5f121b82b650 |<br>| cell0 | 00000000-0000-0000-0000-000000000000 |<br>+——-+————————————–+<br>完成安装启动计算服务并将其配置为在系统引导时启动：</p>
<h1 id="systemctl-enable-openstack-nova-api-service"><a href="#systemctl-enable-openstack-nova-api-service" class="headerlink" title="systemctl enable openstack-nova-api.service \"></a>systemctl enable openstack-nova-api.service \</h1><p>  openstack-nova-consoleauth.service openstack-nova-scheduler.service \<br>  openstack-nova-conductor.service openstack-nova-novncproxy.service</p>
<h1 id="systemctl-start-openstack-nova-api-service"><a href="#systemctl-start-openstack-nova-api-service" class="headerlink" title="systemctl start openstack-nova-api.service \"></a>systemctl start openstack-nova-api.service \</h1><p>  openstack-nova-consoleauth.service openstack-nova-scheduler.service \<br>  openstack-nova-conductor.service openstack-nova-novncproxy.service</p>
<p>五、    计算服务—计算节点配置（Compute service – nova installation for Pike）<br>本节介绍如何在计算节点上安装和配置Compute服务。该服务支持多个虚拟机管理程序来部署实例或虚拟机（VM）。为简单起见，此配置在计算节点上使用Quick EMUlator（QEMU）管理程序和基于内核的VM（KVM）扩展，以支持虚拟机的硬件加速。在传统硬件上，此配置使用通用QEMU管理程序。您可以按照这些说明进行小的修改，以便使用其他计算节点水平扩展您的环境。<br>5.1 安装和配置部件<br>安装软件包：</p>
<h1 id="yum-install-openstack-nova-compute"><a href="#yum-install-openstack-nova-compute" class="headerlink" title="yum install openstack-nova-compute"></a>yum install openstack-nova-compute</h1><p>编辑/etc/nova/nova.conf文件并完成以下操作在该[DEFAULT]部分中，仅启用计算API和元数据API：<br>[DEFAULT]</p>
<h1 id="…-21"><a href="#…-21" class="headerlink" title="…"></a>…</h1><p>enabled_apis = osapi_compute,metadata<br>在该[DEFAULT]部分中，配置RabbitMQ消息队列访问：<br>[DEFAULT]</p>
<h1 id="…-22"><a href="#…-22" class="headerlink" title="…"></a>…</h1><p>transport_url = rabbit://openstack:RABBIT_PASS@controller<br>注：替换RABBIT_PASS为您为该openstack 帐户选择的密码RabbitMQ。<br>在[api]和[keystone_authtoken]部分中，配置身份服务访问：<br>[api]</p>
<h1 id="…-23"><a href="#…-23" class="headerlink" title="…"></a>…</h1><p>auth_strategy = keystone</p>
<p>[keystone_authtoken]</p>
<h1 id="…-24"><a href="#…-24" class="headerlink" title="…"></a>…</h1><p>auth_uri = <a href="http://controller:5000" target="_blank" rel="noopener">http://controller:5000</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>memcached_servers = controller:11211<br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>project_name = service<br>username = nova<br>password = NOVA_PASS<br>注：替换NOVA_PASS为您nova在身份识别服务中为用户选择的密码。<br>在该[DEFAULT]部分中，配置my_ip选项：<br>[DEFAULT]</p>
<h1 id="…-25"><a href="#…-25" class="headerlink" title="…"></a>…</h1><p>my_ip = MANAGEMENT_INTERFACE_IP_ADDRESS<br>注：替换MANAGEMENT_INTERFACE_IP_ADDRESS为计算节点上管理网络接口的IP地址，典型值为10.0.0.31，用于示例体系结构中的第一个节点。<br>在本[DEFAULT]节中，启用对网络服务的支持：<br>[DEFAULT]</p>
<h1 id="…-26"><a href="#…-26" class="headerlink" title="…"></a>…</h1><p>use_neutron = True<br>firewall_driver = nova.virt.firewall.NoopFirewallDriver<br>在本[vnc]节中，启用并配置远程控制台访问：<br>[vnc]</p>
<h1 id="…-27"><a href="#…-27" class="headerlink" title="…"></a>…</h1><p>enabled = True<br>vncserver_listen = 0.0.0.0<br>vncserver_proxyclient_address = $my_ip<br>novncproxy_base_url = <a href="http://controller:6080/vnc_auto.html" target="_blank" rel="noopener">http://controller:6080/vnc_auto.html</a><br>注：服务器组件侦听所有IP地址，并且代理组件只侦听计算节点的管理接口IP地址。基本URL指示您可以使用Web浏览器访问此计算节点上实例的远程控制台的位置。<br>注：如果用于访问远程控制台的Web浏览器驻留在无法解析controller主机名的主机上，则必须controller使用控制器节点的管理接口IP地址进行替换。<br> 在该[glance]部分中，配置Image Service API的位置：<br>[glance]</p>
<h1 id="…-28"><a href="#…-28" class="headerlink" title="…"></a>…</h1><p>api_servers = <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a><br>在该[oslo_concurrency]部分中，配置锁定路径：<br>[oslo_concurrency]</p>
<h1 id="…-29"><a href="#…-29" class="headerlink" title="…"></a>…</h1><p>lock_path = /var/lib/nova/tmp<br>在该[placement]部分中，配置Placement API：<br>[placement]</p>
<h1 id="…-30"><a href="#…-30" class="headerlink" title="…"></a>…</h1><p>os_region_name = RegionOne<br>project_domain_name = Default<br>project_name = service<br>auth_type = password<br>user_domain_name = Default<br>auth_url = <a href="http://controller:35357/v3" target="_blank" rel="noopener">http://controller:35357/v3</a><br>username = placement<br>password = PLACEMENT_PASS<br>注：替换PLACEMENT_PASS为您placement在身份识别服务中为用户选择的密码 。注释本[placement]节中的任何其他选项。<br>5.2 完成安装<br>确定您的计算节点是否支持虚拟机的硬件加速：<br>$ egrep -c ‘(vmx|svm)’ /proc/cpuinfo<br>注：如果此命令返回值，则您的计算节点支持通常不需要额外配置的硬件加速。one or greater如果此命令返回值zero，则您的计算节点不支持硬件加速，您必须配置libvirt为使用QEMU而不是KVM。<br>按如下方式编辑文件中的[libvirt]部分/etc/nova/nova.conf：<br>[libvirt]</p>
<h1 id="…-31"><a href="#…-31" class="headerlink" title="…"></a>…</h1><p>virt_type = qemu<br>启动Compute服务（包括其依赖项）并将其配置为在系统引导时自动启动：</p>
<h1 id="systemctl-enable-libvirtd-service-openstack-nova-compute-service"><a href="#systemctl-enable-libvirtd-service-openstack-nova-compute-service" class="headerlink" title="systemctl enable libvirtd.service openstack-nova-compute.service"></a>systemctl enable libvirtd.service openstack-nova-compute.service</h1><h1 id="systemctl-start-libvirtd-service-openstack-nova-compute-service"><a href="#systemctl-start-libvirtd-service-openstack-nova-compute-service" class="headerlink" title="systemctl start libvirtd.service openstack-nova-compute.service"></a>systemctl start libvirtd.service openstack-nova-compute.service</h1><p>注：如果nova-compute服务无法启动，请检查 /var/log/nova/nova-compute.log。错误消息可能表示控制器节点上的防火墙阻止访问端口5672.配置防火墙以打开控制器节点上的端口5672，并 在计算节点上重新启动服务。AMQP server on controller:5672 is unreachablenova-compute。<br>5.3 将计算节点添加到单元数据库<br>在控制器节点上运行以下命令。<br>输入管理员凭据以启用仅限管理员的CLI命令，然后确认数据库中有计算主机：<br>$ . admin-openrc</p>
<p>$ openstack compute service list –service nova-compute<br>+—-+——-+————–+——+——-+———+—————————-+<br>| ID | Host  | Binary       | Zone | State | Status  | Updated At                 |<br>+—-+——-+————–+——+——-+———+—————————-+<br>| 1  | node1 | nova-compute | nova | up    | enabled | 2017-04-14T15:30:44.000000 |<br>+—-+——-+————–+——+——-+———+—————————-+<br>发现计算主机：</p>
<h1 id="su-s-bin-sh-c-“nova-manage-cell-v2-discover-hosts-–verbose”-nova"><a href="#su-s-bin-sh-c-“nova-manage-cell-v2-discover-hosts-–verbose”-nova" class="headerlink" title="su -s /bin/sh -c “nova-manage cell_v2 discover_hosts –verbose” nova"></a>su -s /bin/sh -c “nova-manage cell_v2 discover_hosts –verbose” nova</h1><p>Found 2 cell mappings.<br>Skipping cell0 since it does not contain hosts.<br>Getting compute nodes from cell ‘cell1’: ad5a5985-a719-4567-98d8-8d148aaae4bc<br>Found 1 computes in cell: ad5a5985-a719-4567-98d8-8d148aaae4bc<br>Checking host mapping for compute host ‘compute’: fe58ddc1-1d65-4f87-9456-bc040dc106b3<br>Creating host mapping for compute host ‘compute’: fe58ddc1-1d65-4f87-9456-bc040dc106b3</p>
<p>注：当您添加新的计算节点时，您必须在控制器节点上运行以注册这些新的计算节点。或者，您可以在以下位置设置适当的间隔 ：nova-manage cell_v2 discover_hosts/etc/nova/nova.conf：<br>[scheduler]<br>discover_hosts_in_cells_interval = 300<br>5.6 验证操作<br>验证Compute服务的操作。在控制器节点上执行这些命令。<br>来源admin凭据来访问仅管理员CLI命令：<br>. admin-openrc<br>列出服务组件以验证每个进程的成功启动和注册：<br>$ openstack compute service list</p>
<p>+—-+——————–+————+———-+———+——-+—————————-+<br>| Id | Binary             | Host       | Zone     | Status  | State | Updated At                 |<br>+—-+——————–+————+———-+———+——-+—————————-+<br>|  1 | nova-consoleauth   | controller | internal | enabled | up    | 2016-02-09T23:11:15.000000 |<br>|  2 | nova-scheduler     | controller | internal | enabled | up    | 2016-02-09T23:11:15.000000 |<br>|  3 | nova-conductor     | controller | internal | enabled | up    | 2016-02-09T23:11:16.000000 |<br>|  4 | nova-compute       | compute1   | nova     | enabled | up    | 2016-02-09T23:11:20.000000 |<br>+—-+——————–+————+———-+———+——-+—————————-+</p>
<p>注：此输出应指示在控制器节点上启用三个服务组件，并在计算节点上启用一个服务组件。<br>列出身份服务中的API端点以验证与身份服务的连接：<br>$ openstack catalog list</p>
<p>+———–+———–+—————————————–+<br>| Name      | Type      | Endpoints                               |<br>+———–+———–+—————————————–+<br>| keystone  | identity  | RegionOne                               |<br>|           |           |   public: <a href="http://controller:5000/v3/" target="_blank" rel="noopener">http://controller:5000/v3/</a>    |<br>|           |           | RegionOne                               |<br>|           |           |   internal: <a href="http://controller:5000/v3/" target="_blank" rel="noopener">http://controller:5000/v3/</a>  |<br>|           |           | RegionOne                               |<br>|           |           |   admin: <a href="http://controller:35357/v3/" target="_blank" rel="noopener">http://controller:35357/v3/</a>    |<br>|           |           |                                         |<br>| glance    | image     | RegionOne                               |<br>|           |           |   admin: <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a>         |<br>|           |           | RegionOne                               |<br>|           |           |   public: <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a>        |<br>|           |           | RegionOne                               |<br>|           |           |   internal: <a href="http://controller:9292" target="_blank" rel="noopener">http://controller:9292</a>      |<br>|           |           |                                         |<br>| nova      | compute   | RegionOne                               |<br>|           |           |   admin: <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a>    |<br>|           |           | RegionOne                               |<br>|           |           |   internal: <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a> |<br>|           |           | RegionOne                               |<br>|           |           |   public: <a href="http://controller:8774/v2.1" target="_blank" rel="noopener">http://controller:8774/v2.1</a>   |<br>|           |           |                                         |<br>| placement | placement | RegionOne                               |<br>|           |           |   public: <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a>        |<br>|           |           | RegionOne                               |<br>|           |           |   admin: <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a>         |<br>|           |           | RegionOne                               |<br>|           |           |   internal: <a href="http://controller:8778" target="_blank" rel="noopener">http://controller:8778</a>      |<br>|           |           |                                         |<br>+———–+———–+—————————————–+</p>
<p>注：根据OpenStack组件的安装情况，端点列表可能会有所不同。忽略此输出中的任何警告。<br>列出Image服务中的图像以验证与Image服务的连接性：<br>$ openstack image list</p>
<p>+————————————–+————-+————-+<br>| ID                                   | Name        | Status      |<br>+————————————–+————-+————-+<br>| 9a76d9f9-9620-4f2e-8c69-6c5691fae163 | cirros      | active      |<br>+————————————–+————-+————-+<br>检查单元格和展示位置API是否成功运行：</p>
<h1 id="nova-status-upgrade-check"><a href="#nova-status-upgrade-check" class="headerlink" title="nova-status upgrade check"></a>nova-status upgrade check</h1><p>+—————————+<br>| Upgrade Check Results     |<br>+—————————+<br>| Check: Cells v2           |<br>| Result: Success           |<br>| Details: None             |<br>+—————————+<br>| Check: Placement API      |<br>| Result: Success           |<br>| Details: None             |<br>+—————————+<br>| Check: Resource Providers |<br>| Result: Success           |<br>| Details: None             |<br>+—————————+</p>
<p>六、网络服务（Networking service – neutron installation for Pike）<br>6.1  主机联网概述<br>在选择部署的体系结构的每个节点上安装操作系统后，必须配置网络接口。我们建议您禁用任何自动网络管理工具，并手动编辑适用于您的发行版的相应配置文件。有关如何在发行版上配置网络的更多信息，请参阅文档。<br>为了管理目的，所有节点都需要Internet访问，例如软件包安装，安全更新，域名系统（DNS）和网络时间协议（NTP）。在大多数情况下，节点应通过管理网络接口获得Internet访问权限。为了强调网络分离的重要性，示例体系结构使用管理网络的专用地址空间，并假设物理网络基础结构通过网络地址转换（NAT）或其他方法提供Internet访问。示例体系结构为提供商（外部）网络使用可路由的IP地址空间，并假定物理网络基础设施提供直接Internet访问。<br>在提供商网络体系结构中，所有实例都直接连接到提供商网络。在自助（私人）网络体系结构中，实例可以附加到自助服务或提供商网络。自助服务网络可以完全驻留在OpenStack内，或通过提供商网络使用网络地址转换（NAT）提供某种级别的外部网络访问。</p>
<p>示例体系结构假设使用以下网络：<br>使用网关10.0.0.1管理10.0.0.0/24<br>此网络需要网关为所有节点提供Internet访问权限，以便管理用途，如软件包安装，安全更新，域名系统（DNS）和网络时间协议（NTP）。<br>提供程序203.0.113.0/24，网关203.0.113.1<br>该网络需要一个网关来提供对OpenStack环境中的实例的Internet访问。<br>您可以修改这些范围和网关以与您的特定网络基础架构配合使用。<br>网络接口名称因分布而异。传统上，接口使用eth后跟一个序列号。为了涵盖所有变化，本指南将第一个接口称为具有最小号码的接口，将第二个接口称为具有最大号码的接口。<br>除非您打算使用此示例架构中提供的确切配置，否则您必须修改此过程中的网络以符合您的环境。除IP地址外，每个节点还必须按名称解析其他节点。例如，controller名称必须解析为10.0.0.11控制器节点上管理接口的IP地址。<br>控制节点：<br>6.2  配置网络接口<br>编辑/etc/sysconfig/network-scripts/ifcfg-INTERFACE_NAME文件以包含以下内容：（重新启动系统以激活更改。）<br>示例：<br>DEVICE=INTERFACE_NAME<br>TYPE=Ethernet<br>ONBOOT=”yes”<br>BOOTPROTO=”none”<br>6.3  配置域名解析<br>将节点的主机名设置为controller。<br>编辑/etc/hosts文件以包含以下内容：</p>
<h1 id="controller"><a href="#controller" class="headerlink" title="controller"></a>controller</h1><p>10.0.0.11       controller</p>
<h1 id="compute1"><a href="#compute1" class="headerlink" title="compute1"></a>compute1</h1><p>10.0.0.31       compute1</p>
<h1 id="block1"><a href="#block1" class="headerlink" title="block1"></a>block1</h1><p>10.0.0.41       block1</p>
<h1 id="object1"><a href="#object1" class="headerlink" title="object1"></a>object1</h1><p>10.0.0.51       object1</p>
<h1 id="object2"><a href="#object2" class="headerlink" title="object2"></a>object2</h1><p>10.0.0.52       object2<br>警告：某些发行版在/etc/hosts 文件中添加了一个无用的条目，可将实际主机名解析为另一个环回IP地址，例如127.0.1.1。您必须注释掉或删除此条目以防止出现名称解析问题。 不要删除127.0.0.1条目。<br>计算节点通控制节点配置相同，只是把域名解释里的controller修改成compute即可。<br>6.4  验证连接<br>在控制节点上或其他节点上执行一下命令来测试连通性：<br>ping  -c   4   域名<br>七、网络服务先决条件<br>7.1  安装和配置控制器节点<br>在配置OpenStack Networking（neutron）服务之前，您必须创建数据库，服务凭据和API端点。<br>要创建数据库，请完成以下步骤：<br>使用数据库访问客户端以root用户身份连接到数据库服务器：<br>$ mysql -u root -p<br>创建neutron数据库：<br>MariaDB [(none)] CREATE DATABASE neutron;<br>授予对neutron数据库的正确访问权限，并替换 NEUTRON_DBPASS为合适的密码：<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.<em> TO ‘neutron‘@’localhost’ \<br>  IDENTIFIED BY ‘NEUTRON_DBPASS’;<br>MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON neutron.</em> TO ‘neutron‘@’%’ \<br>  IDENTIFIED BY ‘NEUTRON_DBPASS’;<br>来源admin凭据来访问仅管理员CLI命令：<br>$ . admin-openrc<br>要创建服务凭据，请完成以下步骤：<br>创建neutron用户：<br>$ openstack user create –domain default –password-prompt neutron</p>
<p>User Password:<br>Repeat User Password:<br>+———————+———————————-+<br>| Field               | Value                            |<br>+———————+———————————-+<br>| domain_id           | default                          |<br>| enabled             | True                             |<br>| id                  | fdb0f541e28141719b6a43c8944bf1fb |<br>| name                | neutron                          |<br>| options             | {}                               |<br>| password_expires_at | None                             |<br>+———————+———————————-+<br>将admin角色添加到neutron用户：<br>openstack role add –project service –user neutron admin<br>创建neutron服务实体：<br>$ openstack service create –name neutron \<br>  –description “OpenStack Networking” network</p>
<p>+————-+———————————-+<br>| Field       | Value                            |<br>+————-+———————————-+<br>| description | OpenStack Networking             |<br>| enabled     | True                             |<br>| id          | f71529314dab4a4d8eca427e701d209e |<br>| name        | neutron                          |<br>| type        | network                          |<br>+————-+———————————-+<br>创建网络服务API端点：<br>$ openstack endpoint create –region RegionOne \<br>  network public <a href="http://controller:9696" target="_blank" rel="noopener">http://controller:9696</a></p>
<p>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | 85d80a6d02fc4b7683f611d7fc1493a3 |<br>| interface    | public                           |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | f71529314dab4a4d8eca427e701d209e |<br>| service_name | neutron                          |<br>| service_type | network                          |<br>| url          | <a href="http://controller:9696" target="_blank" rel="noopener">http://controller:9696</a>           |<br>+————–+———————————-+</p>
<p>$ openstack endpoint create –region RegionOne \<br>  network internal <a href="http://controller:9696" target="_blank" rel="noopener">http://controller:9696</a></p>
<p>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | 09753b537ac74422a68d2d791cf3714f |<br>| interface    | internal                         |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | f71529314dab4a4d8eca427e701d209e |<br>| service_name | neutron                          |<br>| service_type | network                          |<br>| url          | <a href="http://controller:9696" target="_blank" rel="noopener">http://controller:9696</a>           |<br>+————–+———————————-+</p>
<p>$ openstack endpoint create –region RegionOne \<br>  network admin <a href="http://controller:9696" target="_blank" rel="noopener">http://controller:9696</a></p>
<p>+————–+———————————-+<br>| Field        | Value                            |<br>+————–+———————————-+<br>| enabled      | True                             |<br>| id           | 1ee14289c9374dffb5db92a5c112fc4e |<br>| interface    | admin                            |<br>| region       | RegionOne                        |<br>| region_id    | RegionOne                        |<br>| service_id   | f71529314dab4a4d8eca427e701d209e |<br>| service_name | neutron                          |<br>| service_type | network                          |<br>| url          | <a href="http://controller:9696" target="_blank" rel="noopener">http://controller:9696</a>           |<br>+————–+———————————-+</p>
<p>7.2  配置网络选项<br>注：改配置有两个选项配置<br>您可以使用选项1和2所代表的两种体系结构之一来部署网络服务。<br>选项1部署了仅支持将实例附加到提供者（外部）网络的最简单的可能架构。没有自助服务（专用）网络，路由器或浮动IP地址。只有admin或其他特权用户才能管理提供商网络。<br>选项2增加了选项1，其中支持将实例附加到自助服务网络的第3层服务。该demo或其他非特权用户可以管理自助服务网络，包括提供自助服务和提供商网络之间连接的路由器。此外，浮动IP地址可提供与使用来自外部网络（如Internet）的自助服务网络的实例的连接。<br>自助服务网络通常使用覆盖网络。覆盖网络协议（如VXLAN）包含额外的标头，这些标头会增加开销并减少有效负载或用户数据的可用空间。在不了解虚拟网络基础架构的情况下，实例尝试使用1500字节的默认以太网最大传输单元（MTU）发送数据包。网络服务通过DHCP自动为实例提供正确的MTU值。但是，某些云图像不使用DHCP或忽略DHCP MTU选项并需要使用元数据或脚本进行配置。<br>选择以下网络选项之一来配置特定的服务。之后，返回此处并继续 配置元数据代理。<br>一、    提供商网络<br>二、    自助服务网络<br>7.3  提供商网络配置：<br>在控制节点上安装并配置组件：</p>
<h1 id="yum-install-openstack-neutron-openstack-neutron-ml2"><a href="#yum-install-openstack-neutron-openstack-neutron-ml2" class="headerlink" title="yum install openstack-neutron openstack-neutron-ml2 \"></a>yum install openstack-neutron openstack-neutron-ml2 \</h1><p>  openstack-neutron-linuxbridge ebtables<br>编辑/etc/neutron/neutron.conf文件并完成以下操作在该[database]部分中，配置数据库访问：<br>[database]</p>
<h1 id="…-32"><a href="#…-32" class="headerlink" title="…"></a>…</h1><p>connection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron<br>注：替换NEUTRON_DBPASS为您为数据库选择的密码。<br>在本[DEFAULT]节中，启用Modular Layer 2（ML2）插件并禁用其他插件：<br>[DEFAULT]</p>
<h1 id="…-33"><a href="#…-33" class="headerlink" title="…"></a>…</h1><p>core_plugin = ml2<br>service_plugins =<br>在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问：<br>[DEFAULT]</p>
<h1 id="…-34"><a href="#…-34" class="headerlink" title="…"></a>…</h1><p>transport_url = rabbit://openstack:RABBIT_PASS@controller<br>注：替换RABBIT_PASS为您openstack在RabbitMQ中为帐户选择的密码 。<br>在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问：<br>[DEFAULT]</p>
<h1 id="…-35"><a href="#…-35" class="headerlink" title="…"></a>…</h1><p>auth_strategy = keystone</p>
<p>[keystone_authtoken]</p>
<h1 id="…-36"><a href="#…-36" class="headerlink" title="…"></a>…</h1><p>auth_uri = <a href="http://controller:5000" target="_blank" rel="noopener">http://controller:5000</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>memcached_servers = controller:11211<br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>project_name = service<br>username = neutron<br>password = NEUTRON_PASS<br>注：替换NEUTRON_PASS为您neutron 在身份识别服务中为用户选择的密码。<br>在[DEFAULT]和[nova]部分中，配置网络以通知计算网络拓扑更改：<br>[DEFAULT]</p>
<h1 id="…-37"><a href="#…-37" class="headerlink" title="…"></a>…</h1><p>notify_nova_on_port_status_changes = true<br>notify_nova_on_port_data_changes = true</p>
<p>[nova]</p>
<h1 id="…-38"><a href="#…-38" class="headerlink" title="…"></a>…</h1><p>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>region_name = RegionOne<br>project_name = service<br>username = nova<br>password = NOVA_PASS<br>注：替换NOVA_PASS为您nova 在身份识别服务中为用户选择的密码。<br>在该[oslo_concurrency]部分中，配置锁定路径：<br>[oslo_concurrency]</p>
<h1 id="…-39"><a href="#…-39" class="headerlink" title="…"></a>…</h1><p>lock_path = /var/lib/neutron/tmp</p>
<p>配置Modular Layer 2（ML2）插件<br>ML2插件使用Linux桥接机制为实例构建第2层（桥接和交换）虚拟网络基础结构。<br>编辑/etc/neutron/plugins/ml2/ml2_conf.ini文件并完成以下操作：<br>在本[ml2]节中，启用平面和VLAN网络：<br>[ml2]</p>
<h1 id="…-40"><a href="#…-40" class="headerlink" title="…"></a>…</h1><p>type_drivers = flat,vlan<br>在本[ml2]节中，禁用自助服务网络：<br>[ml2]</p>
<h1 id="…-41"><a href="#…-41" class="headerlink" title="…"></a>…</h1><p>tenant_network_types =<br>在本[ml2]节中，启用Linux桥接机制：<br>[ml2]</p>
<h1 id="…-42"><a href="#…-42" class="headerlink" title="…"></a>…</h1><p>mechanism_drivers = linuxbridge<br>警告：配置ML2插件后，删除type_drivers选项中的值 可能会导致数据库不一致。<br>在该[ml2]部分中，启用端口安全扩展驱动程序：<br>[ml2]</p>
<h1 id="…-43"><a href="#…-43" class="headerlink" title="…"></a>…</h1><p>extension_drivers = port_security<br>在本[ml2_type_flat]节中，将提供者虚拟网络配置为扁平网络：<br>[ml2_type_flat]</p>
<h1 id="…-44"><a href="#…-44" class="headerlink" title="…"></a>…</h1><p>flat_networks = provider<br>在本[securitygroup]节中，使用ipset来提高安全组规则的效率：<br>[securitygroup]</p>
<h1 id="…-45"><a href="#…-45" class="headerlink" title="…"></a>…</h1><p>enable_ipset = true<br>配置linux网桥代理<br>Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础架构并处理安全组。<br>编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作：<br>在本[linux_bridge]节中，将提供者虚拟网络映射到提供者物理网络接口：<br>[linux_bridge]<br>physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME<br>替换PROVIDER_INTERFACE_NAME为底层提供商物理网络接口的名称。<br>在该[vxlan]部分中，禁用VXLAN覆盖网络：<br>[vxlan]<br>enable_vxlan = false<br>在本[securitygroup]节中，启用安全组并配置Linux网桥iptables防火墙驱动程序：<br>[securitygroup]</p>
<h1 id="…-46"><a href="#…-46" class="headerlink" title="…"></a>…</h1><p>enable_security_group = true<br>firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver<br>配置DHCP代理<br>DHCP代理为虚拟网络提供DHCP服务。<br>编辑/etc/neutron/dhcp_agent.ini文件并完成以下操作：<br>在本[DEFAULT]节中，配置Linux网桥接口驱动程序，Dnsmasq DHCP驱动程序，并启用隔离的元数据，以便提供商网络上的实例可以通过网络访问元数据：<br>[DEFAULT]</p>
<h1 id="…-47"><a href="#…-47" class="headerlink" title="…"></a>…</h1><p>interface_driver = linuxbridge<br>dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq<br>enable_isolated_metadata = true<br>返回到网络控制器节点配置。<br>7.4  自助服务网络<br>在控制器节点上安装并配置网络组件。</p>
<h1 id="yum-install-openstack-neutron-openstack-neutron-ml2-1"><a href="#yum-install-openstack-neutron-openstack-neutron-ml2-1" class="headerlink" title="yum install openstack-neutron openstack-neutron-ml2 \"></a>yum install openstack-neutron openstack-neutron-ml2 \</h1><p>  openstack-neutron-linuxbridge ebtables<br>编辑/etc/neutron/neutron.conf文件并完成以下操作在该[database]部分中，配置数据库访问：<br>[database]</p>
<h1 id="…-48"><a href="#…-48" class="headerlink" title="…"></a>…</h1><p>connection = mysql+pymysql://neutron:NEUTRON_DBPASS@controller/neutron<br>注：替换NEUTRON_DBPASS为您为数据库选择的密码。<br>在本[DEFAULT]节中，启用Modular Layer 2（ML2）插件，路由器服务和重叠的IP地址：<br>[DEFAULT]</p>
<h1 id="…-49"><a href="#…-49" class="headerlink" title="…"></a>…</h1><p>core_plugin = ml2<br>service_plugins = router<br>allow_overlapping_ips = true<br>在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问：<br>[DEFAULT]</p>
<h1 id="…-50"><a href="#…-50" class="headerlink" title="…"></a>…</h1><p>transport_url = rabbit://openstack:RABBIT_PASS@controller<br>注：替换RABBIT_PASS为您openstack在RabbitMQ中为帐户选择的密码 。<br>在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问：<br>[DEFAULT]</p>
<h1 id="…-51"><a href="#…-51" class="headerlink" title="…"></a>…</h1><p>auth_strategy = keystone</p>
<p>[keystone_authtoken]</p>
<h1 id="…-52"><a href="#…-52" class="headerlink" title="…"></a>…</h1><p>auth_uri = <a href="http://controller:5000" target="_blank" rel="noopener">http://controller:5000</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>memcached_servers = controller:11211<br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>project_name = service<br>username = neutron<br>password = NEUTRON_PASS<br>注：替换NEUTRON_PASS为您neutron 在身份识别服务中为用户选择的密码。<br>在[DEFAULT]和[nova]部分中，配置网络以通知计算网络拓扑更改：<br>[DEFAULT]</p>
<h1 id="…-53"><a href="#…-53" class="headerlink" title="…"></a>…</h1><p>notify_nova_on_port_status_changes = true<br>notify_nova_on_port_data_changes = true</p>
<p>[nova]</p>
<h1 id="…-54"><a href="#…-54" class="headerlink" title="…"></a>…</h1><p>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>region_name = RegionOne<br>project_name = service<br>username = nova<br>password = NOVA_PASS<br>注：替换NOVA_PASS为您nova 在身份识别服务中为用户选择的密码。<br>在该[oslo_concurrency]部分中，配置锁定路径：<br>[oslo_concurrency]</p>
<h1 id="…-55"><a href="#…-55" class="headerlink" title="…"></a>…</h1><p>lock_path = /var/lib/neutron/tmp<br>配置Modular Layer 2（ML2）插件<br>ML2插件使用Linux桥接机制为实例构建第2层（桥接和交换）虚拟网络基础结构。<br>编辑/etc/neutron/plugins/ml2/ml2_conf.ini文件并完成以下操作在该[ml2]部分中，启用平面，VLAN和VXLAN网络：<br>[ml2]</p>
<h1 id="…-56"><a href="#…-56" class="headerlink" title="…"></a>…</h1><p>type_drivers = flat,vlan,vxlan<br>在本[ml2]节中，启用VXLAN自助服务网络：<br>[ml2]</p>
<h1 id="…-57"><a href="#…-57" class="headerlink" title="…"></a>…</h1><p>tenant_network_types = vxlan<br>在本[ml2]节中，启用Linux桥接和第2层人口机制：<br>[ml2]</p>
<h1 id="…-58"><a href="#…-58" class="headerlink" title="…"></a>…</h1><p>mechanism_drivers = linuxbridge,l2populati<br>警告：配置ML2插件后，删除type_drivers选项中的值 可能会导致数据库不一致。<br>注：Linux网桥代理仅支持VXLAN覆盖网络。<br>在该[ml2]部分中，启用端口安全扩展驱动程序：<br>[ml2]</p>
<h1 id="…-59"><a href="#…-59" class="headerlink" title="…"></a>…</h1><p>extension_drivers = port_security<br>在本[ml2_type_flat]节中，将提供者虚拟网络配置为扁平网络：<br>[ml2_type_flat]</p>
<h1 id="…-60"><a href="#…-60" class="headerlink" title="…"></a>…</h1><p>flat_networks = provider<br>在本[ml2_type_vxlan]节中，为自助服务网络配置VXLAN网络标识符范围：<br>[ml2_type_vxlan]</p>
<h1 id="…-61"><a href="#…-61" class="headerlink" title="…"></a>…</h1><p>vni_ranges = 1:1000<br>在本[securitygroup]节中，使用ipset来提高安全组规则的效率：<br>[securitygroup]</p>
<h1 id="…-62"><a href="#…-62" class="headerlink" title="…"></a>…</h1><p>enable_ipset = true<br>配置Linux网桥代理<br>Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础架构并处理安全组。<br>编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作在本[linux_bridge]节中，将提供者虚拟网络映射到提供者物理网络接口：<br>[linux_bridge]<br>physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME</p>
<p>注：替换PROVIDER_INTERFACE_NAME为底层提供商物理网络接口的名称。<br>在该[vxlan]部分中，启用VXLAN覆盖网络，配置处理覆盖网络的物理网络接口的IP地址，并启用第2层群体：<br>[vxlan]<br>enable_vxlan = true<br>local_ip = OVERLAY_INTERFACE_IP_ADDRESS<br>l2_population = true<br>注：替换OVERLAY_INTERFACE_IP_ADDRESS为处理覆盖网络的底层物理网络接口的IP地址。示例体系结构使用管理接口将流量发送到其他节点。<br>在本[securitygroup]节中，启用安全组并配置Linux网桥iptables防火墙驱动程序：<br>[securitygroup]</p>
<h1 id="…-63"><a href="#…-63" class="headerlink" title="…"></a>…</h1><p>enable_security_group = true<br>firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver<br>配置第3层代理<br>第三层（L3）代理为自助服务虚拟网络提供路由和NAT服务。<br>编辑/etc/neutron/l3_agent.ini文件并完成以下操作在该[DEFAULT]部分中，配置Linux网桥接口驱动程序和外部网络桥接器：<br>[DEFAULT]</p>
<h1 id="…-64"><a href="#…-64" class="headerlink" title="…"></a>…</h1><p>interface_driver = linuxbridge<br>配置DHCP代理<br>DHCP代理为虚拟网络提供DHCP服务。<br>编辑/etc/neutron/dhcp_agent.ini文件并完成以下操作：<br>在本[DEFAULT]节中，配置Linux网桥接口驱动程序，Dnsmasq DHCP驱动程并启用隔离的元数据，以便提供商网络上的实例可以通过网络访问元数据：<br>[DEFAULT]</p>
<h1 id="…-65"><a href="#…-65" class="headerlink" title="…"></a>…</h1><p>interface_driver = linuxbridge<br>dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq<br>enable_isolated_metadata = true<br>返回到网络控制器节点配置。<br>7.5  配置元数据代理<br>元数据代理为实例提供配置信息，例如凭据。<br>编辑/etc/neutron/metadata_agent.ini文件并完成以下操作在该[DEFAULT]部分中，配置元数据主机和共享密钥：<br>[DEFAULT]</p>
<h1 id="…-66"><a href="#…-66" class="headerlink" title="…"></a>…</h1><p>nova_metadata_host = controller<br>metadata_proxy_shared_secret = METADATA_SECRET<br>注：用METADATA_SECRET元数据代理的适当密码替换。<br>配置Compute服务以使用网络服务<br>编辑/etc/nova/nova.conf文件并执行以下操作在该[neutron]部分中，配置访问参数，启用元数据代理并配置秘密：<br>[neutron]</p>
<h1 id="…-67"><a href="#…-67" class="headerlink" title="…"></a>…</h1><p>url = <a href="http://controller:9696" target="_blank" rel="noopener">http://controller:9696</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>region_name = RegionOne<br>project_name = service<br>username = neutron<br>password = NEUTRON_PASS<br>service_metadata_proxy = true<br>metadata_proxy_shared_secret = METADATA_SECRET<br>注：替换NEUTRON_PASS为您neutron 在身份识别服务中为用户选择的密码。<br>替换METADATA_SECRET为您为元数据代理选择的秘密。<br>完成安装<br>网络服务初始化脚本需要/etc/neutron/plugin.ini指向ML2插件配置文件的符号链接 /etc/neutron/plugins/ml2/ml2_conf.ini。如果此符号链接不存在，请使用以下命令创建它：</p>
<h1 id="ln-s-etc-neutron-plugins-ml2-ml2-conf-ini-etc-neutron-plugin-ini"><a href="#ln-s-etc-neutron-plugins-ml2-ml2-conf-ini-etc-neutron-plugin-ini" class="headerlink" title="ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini"></a>ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini</h1><p>填充数据库：</p>
<h1 id="su-s-bin-sh-c-“neutron-db-manage-–config-file-etc-neutron-neutron-conf"><a href="#su-s-bin-sh-c-“neutron-db-manage-–config-file-etc-neutron-neutron-conf" class="headerlink" title="su -s /bin/sh -c “neutron-db-manage –config-file /etc/neutron/neutron.conf \"></a>su -s /bin/sh -c “neutron-db-manage –config-file /etc/neutron/neutron.conf \</h1><p>  –config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head” neutron<br>注：因为脚本需要完整的服务器和插件配置文件，所以稍后会出现数据库填充。<br>重新启动Compute API服务：</p>
<h1 id="systemctl-restart-openstack-nova-api-service"><a href="#systemctl-restart-openstack-nova-api-service" class="headerlink" title="systemctl restart openstack-nova-api.service"></a>systemctl restart openstack-nova-api.service</h1><p>启动网络服务并将其配置为在系统引导时启动。对于这两种网络选项：</p>
<h1 id="systemctl-enable-neutron-server-service"><a href="#systemctl-enable-neutron-server-service" class="headerlink" title="systemctl enable neutron-server.service \"></a>systemctl enable neutron-server.service \</h1><p>  neutron-linuxbridge-agent.service neutron-dhcp-agent.service \<br>  neutron-metadata-agent.service</p>
<h1 id="systemctl-start-neutron-server-service"><a href="#systemctl-start-neutron-server-service" class="headerlink" title="systemctl start neutron-server.service \"></a>systemctl start neutron-server.service \</h1><p>  neutron-linuxbridge-agent.service neutron-dhcp-agent.service \<br>  neutron-metadata-agent.service<br>注：如果在此处启动neutron.service出现错误，查看日志出现以下错误，解决办法：</p>
<p>通过查看日志文件报出此错误可能是以下两种错误/etc/neutron/neutron.conf配置文件中core_plugin =xxx名字写错或者没写。<br>1、</p>
<p>2、<br>还有可能是没有l2populati配置文件，这里咱们去/etc/neutron/plugins/ml2/ml2_conf.ini文件里把他删除就可以成功启动了。</p>
<p>对于网络选项2，还启用并启动第3层服务：</p>
<h1 id="systemctl-enable-neutron-l3-agent-service"><a href="#systemctl-enable-neutron-l3-agent-service" class="headerlink" title="systemctl enable neutron-l3-agent.service"></a>systemctl enable neutron-l3-agent.service</h1><h1 id="systemctl-start-neutron-l3-agent-service"><a href="#systemctl-start-neutron-l3-agent-service" class="headerlink" title="systemctl start neutron-l3-agent.service"></a>systemctl start neutron-l3-agent.service</h1><p>7.6  安装和配置计算节点<br>安装组件：<br>网络通用组件配置包括认证机制，消息队列和插件。</p>
<h1 id="yum-install-openstack-neutron-linuxbridge-ebtables-ipset"><a href="#yum-install-openstack-neutron-linuxbridge-ebtables-ipset" class="headerlink" title="yum install openstack-neutron-linuxbridge ebtables ipset"></a>yum install openstack-neutron-linuxbridge ebtables ipset</h1><p>编辑/etc/neutron/neutron.conf文件并完成以下操作在该[database]部分中，注释掉任何connection选项，因为计算节点不直接访问数据库，在该[DEFAULT]部分中，配置RabbitMQ 消息队列访问：<br>[DEFAULT]</p>
<h1 id="…-68"><a href="#…-68" class="headerlink" title="…"></a>…</h1><p>transport_url = rabbit://openstack:RABBIT_PASS@controller<br>注：替换RABBIT_PASS为您openstack 在RabbitMQ中为帐户选择的密码。<br>在[DEFAULT]和[keystone_authtoken]部分中，配置身份服务访问：<br>[DEFAULT]</p>
<h1 id="…-69"><a href="#…-69" class="headerlink" title="…"></a>…</h1><p>auth_strategy = keystone</p>
<p>[keystone_authtoken]</p>
<h1 id="…-70"><a href="#…-70" class="headerlink" title="…"></a>…</h1><p>auth_uri = <a href="http://controller:5000" target="_blank" rel="noopener">http://controller:5000</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>memcached_servers = controller:11211<br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>project_name = service<br>username = neutron<br>password = NEUTRON_PASS<br>注：替换NEUTRON_PASS为您neutron 在身份识别服务中为用户选择的密码<br>在该[oslo_concurrency]部分中，配置锁定路径：<br>[oslo_concurrency]</p>
<h1 id="…-71"><a href="#…-71" class="headerlink" title="…"></a>…</h1><p>lock_path = /var/lib/neutron/tmp<br>7.7  计算节点——提供商网络<br>在计算节点上网络配置选项也分两种：<br>一、    提供商网络<br>二、    自助服务网络<br>下面先做提供商网络：<br>在计算节点上配置网络组件。<br>配置Linux网桥代理Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础架构并处理安全组。编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作：在本[linux_bridge]节中，将提供者虚拟网络映射到提供者物理网络接口：<br>[linux_bridge]<br>physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME<br>注：替换PROVIDER_INTERFACE_NAME为底层提供商物理网络接口的名称。<br>在该[vxlan]部分中，禁用VXLAN覆盖网络：<br>[vxlan]<br>enable_vxlan = false<br>在本[securitygroup]节中，启用安全组并配置Linux网桥iptables防火墙驱动程序：<br>[securitygroup]</p>
<h1 id="…-72"><a href="#…-72" class="headerlink" title="…"></a>…</h1><p>enable_security_group = true<br>firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver<br>返回到网络计算节点配置。<br>7.8  计算节点——自助网络服务<br>在计算节点上配置网络组件。<br>配置Linux网桥代理<br>Linux网桥代理为实例构建第2层（桥接和交换）虚拟网络基础架构并处理安全组。编辑/etc/neutron/plugins/ml2/linuxbridge_agent.ini文件并完成以下操作在本[linux_bridge]节中，将提供者虚拟网络映射到提供者物理网络接口：<br>[linux_bridge]<br>physical_interface_mappings = provider:PROVIDER_INTERFACE_NAME<br>注：替换PROVIDER_INTERFACE_NAME为底层提供商物理网络接口的名称。<br>在该[vxlan]部分中，启用VXLAN覆盖网络，配置处理覆盖网络的物理网络接口的IP地址，并启用第2层群体：<br>[vxlan]<br>enable_vxlan  =  true<br>local_ip  =  OVERLAY_INTERFACE_IP_ADDRESS<br>l2_population  =  true<br>注：替换OVERLAY_INTERFACE_IP_ADDRESS为处理覆盖网络的底层物理网络接口的IP地址。示例体系结构使用管理接口将流量发送到其他节点。因此，请替换OVERLAY_INTERFACE_IP_ADDRESS计算节点的管理IP地址。<br>在本[securitygroup]节中，启用安全组并配置Linux网桥iptables防火墙驱动程序：<br>[securitygroup]<br>＃…<br>enable_security_group  =  true<br>firewall_driver  =  neutron.agent.linux.iptables_firewall.IptablesFirewallDriver<br>返回到网络计算节点配置。<br>7.9  配置Compute网络服务<br>编辑/etc/nova/nova.conf文件并完成以下操作在该[neutron]部分中，配置访问参数：<br>[neutron]</p>
<h1 id="…-73"><a href="#…-73" class="headerlink" title="…"></a>…</h1><p>url = <a href="http://controller:9696" target="_blank" rel="noopener">http://controller:9696</a><br>auth_url = <a href="http://controller:35357" target="_blank" rel="noopener">http://controller:35357</a><br>auth_type = password<br>project_domain_name = default<br>user_domain_name = default<br>region_name = RegionOne<br>project_name = service<br>username = neutron<br>password = NEUTRON_PASS<br>注：替换NEUTRON_PASS为您neutron 在身份识别服务中为用户选择的密码。<br>重新启动计算服务：</p>
<h1 id="systemctl-restart-openstack-nova-compute-service"><a href="#systemctl-restart-openstack-nova-compute-service" class="headerlink" title="systemctl restart openstack-nova-compute.service"></a>systemctl restart openstack-nova-compute.service</h1><p>启动Linux桥代理并将其配置为在系统引导时启动：</p>
<h1 id="systemctl-enable-neutron-linuxbridge-agent-service"><a href="#systemctl-enable-neutron-linuxbridge-agent-service" class="headerlink" title="systemctl enable neutron-linuxbridge-agent.service"></a>systemctl enable neutron-linuxbridge-agent.service</h1><h1 id="systemctl-start-neutron-linuxbridge-agent-service"><a href="#systemctl-start-neutron-linuxbridge-agent-service" class="headerlink" title="systemctl start neutron-linuxbridge-agent.service"></a>systemctl start neutron-linuxbridge-agent.service</h1><p>7.10 验证操作<br>在控制节点上做一下操作。。。<br>提供商网络的验证操作：<br>列出代理以验证中子代理的成功发射：<br>$ openstack network agent list</p>
<p>+————————————–+——————–+————+——————-+——-+——-+—————————+<br>| ID                                   | Agent Type         | Host       | Availability Zone | Alive | State | Binary                    |<br>+————————————–+——————–+————+——————-+——-+——-+—————————+<br>| 0400c2f6-4d3b-44bc-89fa-99093432f3bf | Metadata agent     | controller | None              | True  | UP    | neutron-metadata-agent    |<br>| 83cf853d-a2f2-450a-99d7-e9c6fc08f4c3 | DHCP agent         | controller | nova              | True  | UP    | neutron-dhcp-agent        |<br>| ec302e51-6101-43cf-9f19-88a78613cbee | Linux bridge agent | compute    | None              | True  | UP    | neutron-linuxbridge-agent |<br>| fcb9bc6e-22b1-43bc-9054-272dd517d025 | Linux bridge agent | controller | None              | True  | UP    | neutron-linuxbridge-agent |<br>+————————————–+——————–+————+——————-+——-+——-+—————————+<br>输出应该指示控制器节点上的三个代理和每个计算节点上的一个代理。<br>自助网络服务的验证操作：<br>列出代理以验证中子代理的成功发射：<br>openstack network agent list</p>
<p>+————————————–+——————–+————+——————-+——-+——-+—————————+<br>| ID                                   | Agent Type         | Host       | Availability Zone | Alive | State | Binary                    |<br>+————————————–+——————–+————+——————-+——-+——-+—————————+<br>| 0400c2f6-4d3b-44bc-89fa-99093432f3bf | Metadata agent     | controller | None              | True  | UP    | neutron-metadata-agent    |<br>| 83cf853d-a2f2-450a-99d7-e9c6fc08f4c3 | DHCP agent         | controller | nova              | True  | UP    | neutron-dhcp-agent        |<br>| ec302e51-6101-43cf-9f19-88a78613cbee | Linux bridge agent | compute    | None              | True  | UP    | neutron-linuxbridge-agent |<br>| fcb9bc6e-22b1-43bc-9054-272dd517d025 | Linux bridge agent | controller | None              | True  | UP    | neutron-linuxbridge-agent |<br>+————————————–+——————–+————+——————-+——-+——-+—————————+<br>输出应该指示控制器节点上的三个代理和每个计算节点上的一个代理。<br>八、创建实例<br>注：本节服务可以不用先做，可以等做完openstack  dashboard  服务以后使用B/S架构的web界面去创建实例，web界面更直观方便。<br>本节创建必要的虚拟网络以支持启动实例。网络选项1包括一个提供商（外部）网络，其中一个实例使用它。网络选项2包括一个提供商网络，其中一个使用它的实例和一个自助服务（专用）网络以及一个使用它的实例。本节中的说明使用控制器节点上的命令行界面（CLI）工具。但是，您可以按照安装工具的任何主机上的说明进行操作。有关CLI工具的更多信息，请参阅 Pike 的OpenStackClient文档或Queens的 OpenStackClient文档。要使用仪表板，请参阅 Pike 或 Dashboard的仪表板用户文档Queens的仪表板用户文档。<br>注：本节选用提供商网络。如需配置其他网络请参考：<a href="https://docs.openstack.org/install-guide/launch-instance.html#launch-instance-networks" target="_blank" rel="noopener">https://docs.openstack.org/install-guide/launch-instance.html#launch-instance-networks</a> 来做详细配置。<br>8.1创建提供者网络<br>在控制器节点上，输入admin凭据以访问仅限管理员的CLI命令：<br>$ . admin-openrc<br>创建网络：<br>$ openstack network create  –share –external \<br>  –provider-physical-network provider \<br>  –provider-network-type flat provider</p>
<p>Created a new network:</p>
<p>+—————————+————————————–+<br>| Field                     | Value                                |<br>+—————————+————————————–+<br>| admin_state_up            | UP                                   |<br>| availability_zone_hints   |                                      |<br>| availability_zones        |                                      |<br>| created_at                | 2017-03-14T14:37:39Z                 |<br>| description               |                                      |<br>| dns_domain                | None                                 |<br>| id                        | 54adb94a-4dce-437f-a33b-e7e2e7648173 |<br>| ipv4_address_scope        | None                                 |<br>| ipv6_address_scope        | None                                 |<br>| is_default                | None                                 |<br>| mtu                       | 1500                                 |<br>| name                      | provider                             |<br>| port_security_enabled     | True                                 |<br>| project_id                | 4c7f48f1da5b494faaa66713686a7707     |<br>| provider:network_type     | flat                                 |<br>| provider:physical_network | provider                             |<br>| provider:segmentation_id  | None                                 |<br>| qos_policy_id             | None                                 |<br>| revision_number           | 3                                    |<br>| router:external           | External                             |<br>| segments                  | None                                 |<br>| shared                    | True                                 |<br>| status                    | ACTIVE                               |<br>| subnets                   |                                      |<br>| updated_at                | 2017-03-14T14:37:39Z                 |<br>+—————————+————————————–+<br>该–share选项允许所有项目使用虚拟网络。<br>该–external选项将虚拟网络定义为外部。如果你想创建一个内部网络，你可以使用–internal。默认值是internal。<br>在和 选项平坦虚拟网络连接到平的（天然的/未标记的）的物理上的网络使用从以下文件的信息在主机上的接口：–provider-physical-network provider–provider-network-type flateth1<br>ml2_conf.ini：<br>[ml2_type_flat]<br>flat_networks = provider<br>linuxbridge_agent.ini：<br>[linux_bridge]<br>physical_interface_mappings = provider:eth1<br>在网络上创建一个子网：<br> 注意：这里的命令一定要注意缩进，缩进打不准命令会报错。<br>$ openstack subnet create –network provider \<br>  –allocation-pool start=173.168.6.20,end=173.168.6.250 \<br>  –dns-nameserver 114.114.114.114 –gateway 173.168.6.254 \<br>  –subnet-range 173.168.6.0/24 provider<br>PROVIDER_NETWORK_CIDR以CIDR表示法替换为提供商物理网络上的子网。更换START_IP_ADDRESS和END_IP_ADDRESS与要分配的情况下，子网内的范围内的第一个和最后一个IP地址。该范围不得包含任何现有的活动IP地址。<br>替换DNS_RESOLVER为DNS解析器的IP地址。在大多数情况下，您可以使用/etc/resolv.conf主机上文件中的一个。<br>替换PROVIDER_NETWORK_GATEWAY为提供商网络上的网关IP地址，通常为“.1”IP地址。<br>例：提供商网络在173.168.6.0/24上使用173.168.6.254/24和网关。DHCP服务器为每个实例分配一个从173.168.6.15到173.168.6.250的IP地址。所有实例都使用114.114.114.114作为DNS解析器。<br>创建子网：<br>openstack subnet create –network provider \<br>  –allocation-pool start=173.168.6.20,end=173.168.6.250 \<br>  –dns-nameserver 114.114.114.114 –gateway 173.168.6.254 \<br>  –subnet-range 173.168.6.0/24 provider</p>
<p>Created a new subnet:<br>+——————-+————————————–+<br>| Field             | Value                                |<br>+——————-+————————————–+<br>| allocation_pools  | 173.168.6.15-173.168.6.250        |<br>| cidr              | 173.168.6.0/24                       |<br>| created_at        | 2017-03-29T05:48:29Z                 |<br>| description       |                                      |<br>| dns_nameservers   | 114.114.114.114                    |<br>| enable_dhcp       | True                                 |<br>| gateway_ip        | 173.168.6.254                          |<br>| host_routes       |                                      |<br>| id                | e84b4972-c7fc-4ce9-9742-fdc845196ac5 |<br>| ip_version        | 4                                    |<br>| ipv6_address_mode | None                                 |<br>| ipv6_ra_mode      | None                                 |<br>| name              | provider                             |<br>| network_id        | 1f816a46-7c3f-4ccf-8bf3-fe0807ddff8d |<br>| project_id        | 496efd248b0c46d3b80de60a309177b5     |<br>| revision_number   | 2                                    |<br>| segment_id        | None                                 |<br>| service_types     |                                      |<br>| subnetpool_id     | None                                 |<br>| updated_at        | 2017-03-29T05:48:29Z                 |<br>+——————-+————————————–+</p>
<p>8.2创建m1.nano虚拟网络<br>最小的默认风格消耗每个实例512 MB的内存。对于计算节点内存小于4 GB的环境，我们建议创建m1.nano每个实例仅需要64 MB 的风格。为了测试目的，请仅将CirrOS图像的这种味道使用。<br>来源demo项目凭证：<br>$ openstack flavor create –id 0 –vcpus 1 –ram 64 –disk 1 m1.nano</p>
<p>+—————————-+———+<br>| Field                      | Value   |<br>+—————————-+———+<br>| OS-FLV-DISABLED:disabled   | False   |<br>| OS-FLV-EXT-DATA:ephemeral  | 0       |<br>| disk                       | 1       |<br>| id                         | 0       |<br>| name                       | m1.nano |<br>| os-flavor-access:is_public | True    |<br>| properties                 |         |<br>| ram                        | 64      |<br>| rxtx_factor                | 1.0     |<br>| swap                       |         |<br>| vcpus                      | 1       |<br>+—————————-+———+<br>生成密钥对并添加公钥：<br>$ . demo-openrc</p>
<p>$ ssh-keygen -q -N “”<br>$ openstack keypair create –public-key ~/.ssh/id_rsa.pub mykey</p>
<p>+————-+————————————————-+<br>| Field       | Value                                           |<br>+————-+————————————————-+<br>| fingerprint | ee:3d:2e:97:d4:e2:6a:54:6d:0d:ce:43:39:2c:ba:4d |<br>| name        | mykey                                           |<br>| user_id     | 58126687cbcc4888bfa9ab73a2256f27                |<br>+————-+————————————————-+<br>注意：或者，您可以跳过该ssh-keygen命令并使用现有的公钥，使用现有的公钥默认回车。<br>验证密钥对的添加：<br>$ openstack keypair list</p>
<p>+——-+————————————————-+<br>| Name  | Fingerprint                                     |<br>+——-+————————————————-+<br>| mykey | ee:3d:2e:97:d4:e2:6a:54:6d:0d:ce:43:39:2c:ba:4d |<br>+——-+————————————————-+<br>8.2 添加安全组规则<br>默认情况下，default安全组适用于所有实例，并包含拒绝远程访问实例的防火墙规则。对于像CirrOS这样的Linux映像，我们建议至少允许ICMP（ping）和安全shell（SSH）。<br>向default安全组添加规则：<br>允许ICMP（ping）：<br>$ openstack security group rule create –proto icmp default</p>
<p>+——————-+————————————–+<br>| Field             | Value                                |<br>+——————-+————————————–+<br>| created_at        | 2017-03-30T00:46:43Z                 |<br>| description       |                                      |<br>| direction         | ingress                              |<br>| ether_type        | IPv4                                 |<br>| id                | 1946be19-54ab-4056-90fb-4ba606f19e66 |<br>| name              | None                                 |<br>| port_range_max    | None                                 |<br>| port_range_min    | None                                 |<br>| project_id        | 3f714c72aed7442681cbfa895f4a68d3     |<br>| protocol          | icmp                                 |<br>| remote_group_id   | None                                 |<br>| remote_ip_prefix  | 0.0.0.0/0                            |<br>| revision_number   | 1                                    |<br>| security_group_id | 89ff5c84-e3d1-46bb-b149-e621689f0696 |<br>| updated_at        | 2017-03-30T00:46:43Z                 |<br>+——————-+————————————–+<br>允许安全shell（SSH）访问：<br>$ openstack security group rule create –proto tcp –dst-port 22 default</p>
<p>+——————-+————————————–+<br>| Field             | Value                                |<br>+——————-+————————————–+<br>| created_at        | 2017-03-30T00:43:35Z                 |<br>| description       |                                      |<br>| direction         | ingress                              |<br>| ether_type        | IPv4                                 |<br>| id                | 42bc2388-ae1a-4208-919b-10cf0f92bc1c |<br>| name              | None                                 |<br>| port_range_max    | 22                                   |<br>| port_range_min    | 22                                   |<br>| project_id        | 3f714c72aed7442681cbfa895f4a68d3     |<br>| protocol          | tcp                                  |<br>| remote_group_id   | None                                 |<br>| remote_ip_prefix  | 0.0.0.0/0                            |<br>| revision_number   | 1                                    |<br>| security_group_id | 89ff5c84-e3d1-46bb-b149-e621689f0696 |<br>| updated_at        | 2017-03-30T00:43:35Z                 |<br>+——————-+————————————–+<br>8.3 启动一个实例前的检查<br>在提供商网络上。<br>在控制器节点上，demo获取凭据以访问仅限用户的CLI命令：<br>. demo-openrc<br>风味指定包括处理器，存储器和存储的虚拟资源分配概况。列出可用的风味：<br>$ openstack flavor list</p>
<p>+—-+———+—–+——+———–+——-+———–+<br>| ID | Name    | RAM | Disk | Ephemeral | VCPUs | Is Public |<br>+—-+———+—–+——+———–+——-+———–+<br>| 0  | m1.nano |  64 |    1 |         0 |     1 | True      |<br>+—-+———+—–+——+———–+——-+———–+<br>注：您也可以通过ID引用风味<br>列出可用图像：<br>$ openstack image list</p>
<p>+————————————–+——–+——–+<br>| ID                                   | Name   | Status |<br>+————————————–+——–+——–+<br>| 390eb5f7-8d49-41ec-95b7-68c0d5d54b34 | cirros | active |<br>+————————————–+——–+——–+</p>
<p>这个实例使用cirros图像。<br>列出可用网络：<br>$ openstack network list</p>
<p>+————————————–+————–+————————————–+<br>| ID                                   | Name         | Subnets                              |<br>+————————————–+————–+————————————–+<br>| 4716ddfe-6e60-40e7-b2a8-42e57bf3c31c | selfservice  | 2112d5eb-f9d6-45fd-906e-7cabd38b7c7c |<br>| b5b6993c-ddf9-40e7-91d0-86806a42edb8 | provider     | 310911f6-acf0-4a47-824e-3032916582ff |<br>+————————————–+————–+————————————–+<br>这个实例使用provider提供者网络。但是，您必须使用ID而不是名称来引用此网络。<br>注：如果您选择了选项2，则输出还应包含 selfservice自助服务网络。<br>列出可用的安全组：<br>$ openstack security group list</p>
<p>+————————————–+———+————————+———————————-+<br>| ID                                   | Name    | Description            | Project                          |<br>+————————————–+———+————————+———————————-+<br>| dd2b614c-3dad-48ed-958b-b155a3b38515 | default | Default security group | a516b957032844328896baa01e0f906c |<br>+————————————–+———+————————+———————————-+<br>此实例使用default安全组。<br>8.4 启动一个实例<br>启动实例：替换PROVIDER_NET_ID为provider提供商网络的ID 。<br> 注意：如果您选择了选项1，并且您的环境仅包含一个网络，则可以省略该–nic选项，因为OpenStack会自动选择唯一可用的网络。<br>检查您的实例的状态：<br>$ openstack server create –flavor m1.nano –image cirros \<br>  –nic net-id=PROVIDER_NET_ID –security-group default \<br>  –key-name mykey provider-instance</p>
<p>+—————————–+———————————————–+<br>| Field                       | Value                                         |<br>+—————————–+———————————————–+<br>| OS-DCF:diskConfig           | MANUAL                                        |<br>| OS-EXT-AZ:availability_zone |                                               |<br>| OS-EXT-STS:power_state      | NOSTATE                                       |<br>| OS-EXT-STS:task_state       | scheduling                                    |<br>| OS-EXT-STS:vm_state         | building                                      |<br>| OS-SRV-USG:launched_at      | None                                          |<br>| OS-SRV-USG:terminated_at    | None                                          |<br>| accessIPv4                  |                                               |<br>| accessIPv6                  |                                               |<br>| addresses                   |                                               |<br>| adminPass                   | PwkfyQ42K72h                                  |<br>| config_drive                |                                               |<br>| created                     | 2017-03-30T00:59:44Z                          |<br>| flavor                      | m1.nano (0)                                   |<br>| hostId                      |                                               |<br>| id                          | 36f3130e-cf1b-42f8-a80b-ebd63968940e          |<br>| image                       | cirros (97e06b44-e9ed-4db4-ba67-6e9fc5d0a203) |<br>| key_name                    | mykey                                         |<br>| name                        | provider-instance                             |<br>| progress                    | 0                                             |<br>| project_id                  | 3f714c72aed7442681cbfa895f4a68d3              |<br>| properties                  |                                               |<br>| security_groups             | name=’default’                                |<br>| status                      | BUILD                                         |<br>| updated                     | 2017-03-30T00:59:44Z                          |<br>| user_id                     | 1a421c69342348248c7696e3fd6d4366              |<br>| volumes_attached            |                                               |<br>+—————————–+———————————————–+<br>检查您的实例状态：<br>$ openstack server list</p>
<p>+————————————–+——————-+——–+————————+————+<br>| ID                                   | Name              | Status | Networks               | Image Name |<br>+————————————–+——————-+——–+————————+————+<br>| 181c52ba-aebc-4c32-a97d-2e8e82e4eaaf | provider-instance | ACTIVE | provider=203.0.113.103 | cirros     |<br>+————————————–+——————-+——–+————————+————+<br>状态从改变BUILD到ACTIVE时构建过程成功完成。<br>九、用户界面（Dashboard – horizon installation for Pike）<br>本节介绍如何在控制器节点上安装和配置仪表板。仪表板所需的唯一核心服务是身份服务。您可以将仪表板与其他服务结合使用，例如图像服务，计算和网络。您还可以在具有独立服务（如对象存储）的环境中使用仪表板。<br>必须正确安装Apache HTTP服务器和Memcached服务后，才能配置和操作Identity Service。<br>这里咱们从软件包安装仪表盘。<br>9.1 安装和配置部件<br>安装软件包：</p>
<h1 id="yum-install-openstack-dashboard"><a href="#yum-install-openstack-dashboard" class="headerlink" title="yum install openstack-dashboard"></a>yum install openstack-dashboard</h1><p>编辑 /etc/openstack-dashboard/local_settings 文件并完成以下操作：配置仪表板以在controller节点上使用OpenStack服务 ：<br>注意：在配置文件中配置以下参数时要注意注释掉文件中以前的参数，如果不注释将会产生冲突，使httpd服务启动失败。在做这一步的时候本人比较小心翼翼打一条命令重启一下报不报错，这是一个很好的办法，能有效的检测出是哪里出的错误。<br>OPENSTACK_HOST = “controller”<br>允许您的主机访问仪表板：<br>ALLOWED_HOSTS = [‘one.example.com’, ‘two.example.com’]<br>注意：ALLOWED_HOSTS也可以[‘*’]接受所有主机。这对开发工作可能有用，但可能不安全，不应用于生产。有关 更多信息，请参见：<a href="https://docs.djangoproject.com/en/dev/ref/settings/#allowed-hosts。" target="_blank" rel="noopener">https://docs.djangoproject.com/en/dev/ref/settings/#allowed-hosts。</a><br>配置memcached会话存储服务：<br>SESSION_ENGINE = ‘django.contrib.sessions.backends.cache’</p>
<p>CACHES = {<br>    ‘default’: {<br>         ‘BACKEND’: ‘django.core.cache.backends.memcached.MemcachedCache’,<br>         ‘LOCATION’: ‘controller:11211’,<br>    }<br>}<br>注意：注释掉任何其他会话存储配置。<br>启用Identity API版本3：<br>OPENSTACK_KEYSTONE_URL = “http://%s:5000/v3” % OPENSTACK_HOST<br>启用对域的支持：<br>OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True<br>配置API版本：<br>OPENSTACK_API_VERSIONS = {<br>    “identity”: 3,<br>    “image”: 2,<br>    “volume”: 2,<br>}<br>配置Default为您通过仪表板创建的用户的默认域：<br>OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = “Default”<br>配置user为您通过仪表板创建的用户的默认角色：<br>OPENSTACK_KEYSTONE_DEFAULT_ROLE = “user”<br>如果您选择了网络选项1，请禁用对三层网络服务的支持：<br>OPENSTACK_NEUTRON_NETWORK = {<br>    …<br>    ‘enable_router’: False,<br>    ‘enable_quotas’: False,<br>    ‘enable_distributed_router’: False,<br>    ‘enable_ha_router’: False,<br>    ‘enable_lb’: False,<br>    ‘enable_firewall’: False,<br>    ‘enable_vpn’: False,<br>    ‘enable_fip_topology_check’: False,<br>}<br>（可选）配置时区：<br>TIME_ZONE = “TIME_ZONE”<br>注：替换TIME_ZONE为适当的时区标识符。有关更多信息，请参阅时区列表。<br>9.2 完成安装<br>重新启动Web服务器和会话存储服务：</p>
<h1 id="systemctl-restart-httpd-service-memcached-service"><a href="#systemctl-restart-httpd-service-memcached-service" class="headerlink" title="systemctl restart httpd.service memcached.service"></a>systemctl restart httpd.service memcached.service</h1><p>注：如果当前没有运行，该命令会启动每个服务。systemctl restart<br>9.3 验证连接<br>验证仪表板的操作。使用浏览器访问仪表板 http://本机地址/dashboard。<br>使用admin或demo用户和default域凭据进行身份验证。<br>在验证的时候报错无法访问有点gg，经过小编的不断努力通过查看日志发现一条报错的有用信息：“Scirpt  timed  out  before  returning  headers:django.wsgi” 百度这条关键信息终于找到问题的所在；原因是配置文件出了点问题。需要修改一下 /etc/openstack-dashboard/local_settings ；<br>在WSGISocketPrefixrun/wsgi下面加一行代码：<br>WSGIApplicationGroup  %{GLOBAL} 保存退出，重启httpd服务。<br>听我朋友说他搭建的时候可以访问了但是老是登录失败，这里我没遇到这种情况，在这里我就参考他写作给大家分享一下，老是登录失败呢，查看日志，发现如下报错信息， “Unable  to  create  a  new  session  key.” “Unable  to create   a  new  session  key.  It  is  likely  that  the  cache  is unavailable”我朋友通过百度找到解决问题的所在，需要修改一下  /etc/openstack-dashboard/local_settings 文件中的SESSION_ENGINE=’django.contrib.sessions.backends.cache’将cache修改为file，重启httpd服务即可成功访问。</p>
<p>这里访问的默认域为“Default”，用户名admin，密码为1，也可以使用demo用户登录，demo用户密码也为“1”。</p>
<p>至此 openstack  dashboard 服务搭建完成，也就意味着openstack-pike 服务完整搭建成功。</p>
<p>总结：<br>   通过本次的OpenStack搭建使我收获了很多的知识，同时让我弄懂了OpenStack的架构原理，本次的搭建是一个不断学习党的过程，让我学会了搭建服务遇到问题要耐心，要学会通过查看日志排查错误。<br>特别注意：在执行与数据库相关联的服务时，如果报错就先同步一下数据在做操作，同步完数据库如果报错提示password失踪（Missing value auth-url required for auth plugin password）就重新设置一下路径，这里用 .  admin-openrc。做完以上操作基本上就会没有多少问题。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/11/05/pxe服务器无人值守安装系统搭建/" rel="next" title="pxe服务器无人值守安装系统搭建">
                <i class="fa fa-chevron-left"></i> pxe服务器无人值守安装系统搭建
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">态度</p>
              <p class="site-description motion-element" itemprop="description">记笔记使人成长，好记性不如烂笔头。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-chronyd-service"><span class="nav-number">1.</span> <span class="nav-text">systemctl enable chronyd.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-chronyd-service"><span class="nav-number">2.</span> <span class="nav-text">systemctl start chronyd.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-mariadb-mariadb-server-python2-PyMySQL"><span class="nav-number">3.</span> <span class="nav-text">yum install mariadb mariadb-server python2-PyMySQL</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-mariadb-service"><span class="nav-number">4.</span> <span class="nav-text">systemctl enable mariadb.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-mariadb-service"><span class="nav-number">5.</span> <span class="nav-text">systemctl start mariadb.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#mysql-secure-installation"><span class="nav-number">6.</span> <span class="nav-text">mysql_secure_installation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-rabbitmq-server"><span class="nav-number">7.</span> <span class="nav-text">yum install rabbitmq-server</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-rabbitmq-server-service"><span class="nav-number">8.</span> <span class="nav-text">systemctl enable  rabbitmq-server.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-rabbitmq-server-service"><span class="nav-number">9.</span> <span class="nav-text">systemctl start  rabbitmq-server.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#rabbitmqctl-add-user-openstack-RABBIT-PASS"><span class="nav-number">10.</span> <span class="nav-text">rabbitmqctl add_user openstack RABBIT_PASS</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#rabbitmqctl-set-permissions-openstack-“-“-“-“-“-”"><span class="nav-number">11.</span> <span class="nav-text">rabbitmqctl set_permissions openstack “.“ “.“ “.*”</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-memcached-python-memcached"><span class="nav-number">12.</span> <span class="nav-text">yum install memcached python-memcached</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-memcached-service"><span class="nav-number">13.</span> <span class="nav-text">systemctl enable memcached.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-memcached-service"><span class="nav-number">14.</span> <span class="nav-text">systemctl start memcached.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-etcd"><span class="nav-number">15.</span> <span class="nav-text">yum install etcd</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-etcd"><span class="nav-number">16.</span> <span class="nav-text">systemctl enable etcd</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-etcd"><span class="nav-number">17.</span> <span class="nav-text">systemctl start etcd</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-openstack-keystone-httpd-mod-wsgi"><span class="nav-number">18.</span> <span class="nav-text">yum install openstack-keystone httpd mod_wsgi</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…"><span class="nav-number">19.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-1"><span class="nav-number">20.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#su-s-bin-sh-c-“keystone-manage-db-sync”-keystone"><span class="nav-number">21.</span> <span class="nav-text">su -s /bin/sh -c “keystone-manage db_sync” keystone</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#keystone-manage-fernet-setup-–keystone-user-keystone-–keystone-group-keystone"><span class="nav-number">22.</span> <span class="nav-text">keystone-manage fernet_setup –keystone-user keystone –keystone-group keystone</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#keystone-manage-credential-setup-–keystone-user-keystone-–keystone-group-keystone"><span class="nav-number">23.</span> <span class="nav-text">keystone-manage credential_setup –keystone-user keystone –keystone-group keystone</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#keystone-manage-bootstrap-–bootstrap-password-ADMIN-PASS"><span class="nav-number">24.</span> <span class="nav-text">keystone-manage bootstrap –bootstrap-password ADMIN_PASS \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ln-s-usr-share-keystone-wsgi-keystone-conf-etc-httpd-conf-d"><span class="nav-number">25.</span> <span class="nav-text">ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-httpd-service"><span class="nav-number">26.</span> <span class="nav-text">systemctl enable httpd.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-httpd-service"><span class="nav-number">27.</span> <span class="nav-text">systemctl start httpd.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-openstack-glance"><span class="nav-number">28.</span> <span class="nav-text">yum install openstack-glance</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-2"><span class="nav-number">29.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-3"><span class="nav-number">30.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-4"><span class="nav-number">31.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-5"><span class="nav-number">32.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-6"><span class="nav-number">33.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-7"><span class="nav-number">34.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-8"><span class="nav-number">35.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#su-s-bin-sh-c-“glance-manage-db-sync”-glance"><span class="nav-number">36.</span> <span class="nav-text">su -s /bin/sh -c “glance-manage db_sync” glance</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-openstack-glance-api-service"><span class="nav-number">37.</span> <span class="nav-text">systemctl enable openstack-glance-api.service \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-openstack-glance-api-service"><span class="nav-number">38.</span> <span class="nav-text">systemctl start openstack-glance-api.service \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-openstack-nova-api-openstack-nova-conductor"><span class="nav-number">39.</span> <span class="nav-text">yum install openstack-nova-api openstack-nova-conductor \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-9"><span class="nav-number">40.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-10"><span class="nav-number">41.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-11"><span class="nav-number">42.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-12"><span class="nav-number">43.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-13"><span class="nav-number">44.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-14"><span class="nav-number">45.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-15"><span class="nav-number">46.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-16"><span class="nav-number">47.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-17"><span class="nav-number">48.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-18"><span class="nav-number">49.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-19"><span class="nav-number">50.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-20"><span class="nav-number">51.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-restart-httpd"><span class="nav-number">52.</span> <span class="nav-text">systemctl restart httpd</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#su-s-bin-sh-c-“nova-manage-api-db-sync”-nova"><span class="nav-number">53.</span> <span class="nav-text">su -s /bin/sh -c “nova-manage api_db sync” nova</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#su-s-bin-sh-c-“nova-manage-cell-v2-map-cell0”-nova"><span class="nav-number">54.</span> <span class="nav-text">su -s /bin/sh -c “nova-manage cell_v2 map_cell0” nova</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#su-s-bin-sh-c-“nova-manage-cell-v2-create-cell-–name-cell1-–verbose”-nova"><span class="nav-number">55.</span> <span class="nav-text">su -s /bin/sh -c “nova-manage cell_v2 create_cell –name=cell1 –verbose” nova</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#su-s-bin-sh-c-“nova-manage-db-sync”-nova"><span class="nav-number">56.</span> <span class="nav-text">su -s /bin/sh -c “nova-manage db sync” nova</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#nova-manage-cell-v2-list-cells"><span class="nav-number">57.</span> <span class="nav-text">nova-manage cell_v2 list_cells</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-openstack-nova-api-service"><span class="nav-number">58.</span> <span class="nav-text">systemctl enable openstack-nova-api.service \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-openstack-nova-api-service"><span class="nav-number">59.</span> <span class="nav-text">systemctl start openstack-nova-api.service \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-openstack-nova-compute"><span class="nav-number">60.</span> <span class="nav-text">yum install openstack-nova-compute</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-21"><span class="nav-number">61.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-22"><span class="nav-number">62.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-23"><span class="nav-number">63.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-24"><span class="nav-number">64.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-25"><span class="nav-number">65.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-26"><span class="nav-number">66.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-27"><span class="nav-number">67.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-28"><span class="nav-number">68.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-29"><span class="nav-number">69.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-30"><span class="nav-number">70.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-31"><span class="nav-number">71.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-libvirtd-service-openstack-nova-compute-service"><span class="nav-number">72.</span> <span class="nav-text">systemctl enable libvirtd.service openstack-nova-compute.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-libvirtd-service-openstack-nova-compute-service"><span class="nav-number">73.</span> <span class="nav-text">systemctl start libvirtd.service openstack-nova-compute.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#su-s-bin-sh-c-“nova-manage-cell-v2-discover-hosts-–verbose”-nova"><span class="nav-number">74.</span> <span class="nav-text">su -s /bin/sh -c “nova-manage cell_v2 discover_hosts –verbose” nova</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#nova-status-upgrade-check"><span class="nav-number">75.</span> <span class="nav-text">nova-status upgrade check</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#controller"><span class="nav-number">76.</span> <span class="nav-text">controller</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#compute1"><span class="nav-number">77.</span> <span class="nav-text">compute1</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#block1"><span class="nav-number">78.</span> <span class="nav-text">block1</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#object1"><span class="nav-number">79.</span> <span class="nav-text">object1</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#object2"><span class="nav-number">80.</span> <span class="nav-text">object2</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-openstack-neutron-openstack-neutron-ml2"><span class="nav-number">81.</span> <span class="nav-text">yum install openstack-neutron openstack-neutron-ml2 \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-32"><span class="nav-number">82.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-33"><span class="nav-number">83.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-34"><span class="nav-number">84.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-35"><span class="nav-number">85.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-36"><span class="nav-number">86.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-37"><span class="nav-number">87.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-38"><span class="nav-number">88.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-39"><span class="nav-number">89.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-40"><span class="nav-number">90.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-41"><span class="nav-number">91.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-42"><span class="nav-number">92.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-43"><span class="nav-number">93.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-44"><span class="nav-number">94.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-45"><span class="nav-number">95.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-46"><span class="nav-number">96.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-47"><span class="nav-number">97.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-openstack-neutron-openstack-neutron-ml2-1"><span class="nav-number">98.</span> <span class="nav-text">yum install openstack-neutron openstack-neutron-ml2 \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-48"><span class="nav-number">99.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-49"><span class="nav-number">100.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-50"><span class="nav-number">101.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-51"><span class="nav-number">102.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-52"><span class="nav-number">103.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-53"><span class="nav-number">104.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-54"><span class="nav-number">105.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-55"><span class="nav-number">106.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-56"><span class="nav-number">107.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-57"><span class="nav-number">108.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-58"><span class="nav-number">109.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-59"><span class="nav-number">110.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-60"><span class="nav-number">111.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-61"><span class="nav-number">112.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-62"><span class="nav-number">113.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-63"><span class="nav-number">114.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-64"><span class="nav-number">115.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-65"><span class="nav-number">116.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-66"><span class="nav-number">117.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-67"><span class="nav-number">118.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ln-s-etc-neutron-plugins-ml2-ml2-conf-ini-etc-neutron-plugin-ini"><span class="nav-number">119.</span> <span class="nav-text">ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#su-s-bin-sh-c-“neutron-db-manage-–config-file-etc-neutron-neutron-conf"><span class="nav-number">120.</span> <span class="nav-text">su -s /bin/sh -c “neutron-db-manage –config-file /etc/neutron/neutron.conf \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-restart-openstack-nova-api-service"><span class="nav-number">121.</span> <span class="nav-text">systemctl restart openstack-nova-api.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-neutron-server-service"><span class="nav-number">122.</span> <span class="nav-text">systemctl enable neutron-server.service \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-neutron-server-service"><span class="nav-number">123.</span> <span class="nav-text">systemctl start neutron-server.service \</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-neutron-l3-agent-service"><span class="nav-number">124.</span> <span class="nav-text">systemctl enable neutron-l3-agent.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-neutron-l3-agent-service"><span class="nav-number">125.</span> <span class="nav-text">systemctl start neutron-l3-agent.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-openstack-neutron-linuxbridge-ebtables-ipset"><span class="nav-number">126.</span> <span class="nav-text">yum install openstack-neutron-linuxbridge ebtables ipset</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-68"><span class="nav-number">127.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-69"><span class="nav-number">128.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-70"><span class="nav-number">129.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-71"><span class="nav-number">130.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-72"><span class="nav-number">131.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#…-73"><span class="nav-number">132.</span> <span class="nav-text">…</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-restart-openstack-nova-compute-service"><span class="nav-number">133.</span> <span class="nav-text">systemctl restart openstack-nova-compute.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-enable-neutron-linuxbridge-agent-service"><span class="nav-number">134.</span> <span class="nav-text">systemctl enable neutron-linuxbridge-agent.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-start-neutron-linuxbridge-agent-service"><span class="nav-number">135.</span> <span class="nav-text">systemctl start neutron-linuxbridge-agent.service</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#yum-install-openstack-dashboard"><span class="nav-number">136.</span> <span class="nav-text">yum install openstack-dashboard</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#systemctl-restart-httpd-service-memcached-service"><span class="nav-number">137.</span> <span class="nav-text">systemctl restart httpd.service memcached.service</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">态度</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
